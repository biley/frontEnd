- [1. http/1.0, http/1.1, http/2, http/3](#1-http10-http11-http2-http3)
  - [1.1 http/1.0](#11-http10)
  - [1.2 http/1.1](#12-http11)
  - [1.3 https(HyperText Transfer Protocol over SecureSocket Layer)](#13-httpshypertext-transfer-protocol-over-securesocket-layer)
    - [1.3.1 解决方案](#131-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88)
  - [1.3 SPDY](#13-spdy)
  - [1.4 http/2](#14-http2)
    - [1.4.1 设计和技术目标](#141-%e8%ae%be%e8%ae%a1%e5%92%8c%e6%8a%80%e6%9c%af%e7%9b%ae%e6%a0%87)
    - [1.4.2 二进制分帧层](#142-%e4%ba%8c%e8%bf%9b%e5%88%b6%e5%88%86%e5%b8%a7%e5%b1%82)
    - [1.4.3 数据流、消息和帧：](#143-%e6%95%b0%e6%8d%ae%e6%b5%81%e6%b6%88%e6%81%af%e5%92%8c%e5%b8%a7)
    - [1.4.4 数据流优先级：](#144-%e6%95%b0%e6%8d%ae%e6%b5%81%e4%bc%98%e5%85%88%e7%ba%a7)
    - [1.4.５　每个来源一个连接：](#14%ef%bc%95-%e6%af%8f%e4%b8%aa%e6%9d%a5%e6%ba%90%e4%b8%80%e4%b8%aa%e8%bf%9e%e6%8e%a5)
    - [1.4.6 流控制：](#146-%e6%b5%81%e6%8e%a7%e5%88%b6)
    - [1.4.7 服务器推送：](#147-%e6%9c%8d%e5%8a%a1%e5%99%a8%e6%8e%a8%e9%80%81)
    - [1.4.8 header压缩(HPACK算法)：](#148-header%e5%8e%8b%e7%bc%a9hpack%e7%ae%97%e6%b3%95)
  - [1.5 http/3](#15-http3)
    - [1.5.1 零RTT建立连接](#151-%e9%9b%b6rtt%e5%bb%ba%e7%ab%8b%e8%bf%9e%e6%8e%a5)
    - [1.5.2 连接迁移](#152-%e8%bf%9e%e6%8e%a5%e8%bf%81%e7%a7%bb)
    - [1.5.3 没有队头阻塞的多路复用](#153-%e6%b2%a1%e6%9c%89%e9%98%9f%e5%a4%b4%e9%98%bb%e5%a1%9e%e7%9a%84%e5%a4%9a%e8%b7%af%e5%a4%8d%e7%94%a8)
    - [1.5.4 拥塞控制](#154-%e6%8b%a5%e5%a1%9e%e6%8e%a7%e5%88%b6)
    - [1.5.5 流量控制](#155-%e6%b5%81%e9%87%8f%e6%8e%a7%e5%88%b6)
### 1. http/1.0, http/1.1, http/2, http/3

- http/0.9: 1991年发布，极其简单，只有一个 get 命令;
- http/1.0: 1996年5月发布，增加了大量内容;
- http/1.1: 1999年6月发布，进一步完善 http 协议;
- SPDY: 2009年有 Google 发布，主要解决 http/1.1 效率不高的问题;
- http/2.0: 2015年借鉴SPDY的 http/2 发布;

![http-history](/Image/http-history.png)

![http-protocol](/Image/http-protocol.png)

客户端可以在TCP三次握手第三个报文段中捎带HTTP请求，节省资源。

影响一个http网络请求的因素主要有两个，就是带宽和延迟：
- 带宽：网络带宽指单位时间内传输的数据量，是数据的传输能力。随着网络基础建设较为完善，基本不用担心带宽影响网速。
- 延迟：
  1. 浏览器阻塞(head of line blocking ?): 浏览器对于同一个域名，同时只能有6个连接(根据浏览器内核可能有所差异)，超过浏览器最大连接数限制，后续请求就会被阻塞。这也是为何一些站点会有多个静态资源CDN域名的原因之一。
  2. DNS查询：解析域名为IP,一般使用DNS缓存来减少这个时间。
  3. 建立连接：http基于TCP,浏览器最开也要在第三次握手时才能携带HTTP请求报文，达到真正的连接建立。这些连接若无法复用则会导致每次请求都经历三次握手和慢启动，客户端和服务器也需要不停的分配和回收TCP缓存空间以及变量。三次握手在高延迟场景下影响比较明显，慢开始则对文件类大请求影响较大。

#### 1.1 http/1.0
http/1.0 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都与服务器建立一个TCP连接,服务器完成请求处理后立即断开TCP连接。它的主要问题在于：
1. 一个网页中需要对图片，JS文件，CSS文件发出多个请求，而对每个请求，都需要建立新的连接。
2. 而TCP连接的建立和释放相对费时，且每次建立TCP连接之后都要执行慢开始算法。
3. TCP 连接建立时，客户机和服务器都需要为其分配缓存空间和变量并在连接释放时回收他们。当请求数量大时，这也会影响到客户机和服务器的性能。

http/1.0 中持续连接是关闭的，需要在http header 中加入：`connection: keep-alive; keep-alive: timeout = 5, max = 1000`类似的内容才能持续连接。而 http/1.1 中默认启用持续连接，加入 `connection: close` 才关闭。connection 在 request 和 response 的 header 中均可出现，只要其值为 `close`,则该连接会在请求处理完毕后释放调。http/1.0 中，虽然标准没有规定，但某些服务器对 ``connection: keep-alive` 的 Header 进行了支持。

http/1.1 之前的 http 版本的默认连接都是非持久连接。为此，若想在旧版本的 http 协议上维持持续连接，则需要指定 `Connection` 首部字段的置为 `keep-alive`。 —— 《图解HTTP》

#### 1.2 http/1.1
http/1.1 进一步完善了 http 协议，是目前最流行的版本。
它和 http/1.0 的**主要**区别在于：
1. 缓存处理： 引入了更多的缓存控制策略。
2. 错误状态处理：新增了24个错误状态相应码，如409, 410 等。
3. 范围请求：http/1.0 中，存在一些浪费带宽的现象，如若客户端只需某个对象的一部分，服务器却会将整个对象送过来，且不支持断点续传功能。http/1.1 在请求头引入了 range 头域，它允许值请求资源的某个部分(返回码是206),这样就方便了开发者自由的选择以便充分利用带宽和连接，支持断点续传。
4. Host头：http/1.0 中认为每台服务器都绑定一个唯一的IP地址，因此请求的URL中并没有传递主机名。但随着技术发展，在一台物理服务器上可以存在多个虚拟主机，且它们共享一个IP地址。http/1.1的request 和 response 都支持 host 字段，且若 request 中没有 host 字段会报错(400 bad request)。使用 host 字段，可以将请求发往同一台服务器上的不同网站，为虚拟主机的兴起打下了基础。
5. 持久连接：http/1.1 最大的变化是引入持久连接(http/1.0似乎也可以有，但不是规范)，默认开启 `connection: keep-alive`,即 tcp 连接默认不关闭，可以被多个请求复用。

客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。但规范的做法是客户端在最后一个请求时，发送 `Connection: close`,明确要求服务器关闭TCP连接。

6. 管道机制(pipelining): 在同一个TCP连接中，客户端可以同时发送多个请求(流水线方式)。但现代浏览器中并不默认启用 pipelining，因为它存在一些问题：
   - 一些代理服务器不能正确处理 pipelining。
   - 正确的流水线实现复杂。
   - 流水线受制于 head-of-line-blocking 问题。不使用 pipelining 时，若一个请求响应处理了很久，则之后的请求可能直接走其他的TCP连接，可以一定程度上缓解这个问题。
   - 只有 idempotent 方式的 http 请求才能应用到 pipelining。idempotent 指的是同样的请求被执行一次与执行多次的效果是一样的，服务器的状态也是一样的：get, head, put, delete 方法都是 idempotent 的，而 post 方法不是。应该是因为，如果出现故障，则不知道 pipelining 中哪些请求已经被服务器执行了，所以需要 pipelining 中的请求都可以简单的重传。

![http/1.x-connection](/Image/http1.x-connection.png)

需要注意的是 http 的连接管理适用于两个连续节点之间的连接，如 hop-by-hop, 而不是 end-to-end。如 `Connection`和`Keep-Alive` 就是 `hop-by-hop` 协议头，它们的值是可以被中间结点修改的。

虽然 http/1.1 使用了持久连接和管道机制来复用TCP连接且同时发送多个请求，但所有的数据通信都是按次序完成的，服务器只有处理完一个响应，才会处理下一个响应。因此，有时候若某个请求的处理特别慢，则之后的请求都得排队等着，这成为"队头阻塞(head-of-line-blocking)"。虽然浏览器可以针对单个域名开启6个左右的连接并通过各个连接分别发送请求，能在一定程度上解决这个问题，但每个连接中依然会存在这个问题。

参考：
- [如何优雅的谈论HTTP/1.0，http/1.1，http/2.0](https://www.jianshu.com/p/52d86558ca57)
- [《图解HTTP》](https://kingyinliang.github.io/PDF/%E5%9B%BE%E8%A7%A3HTTP+%E5%BD%A9%E8%89%B2%E7%89%88.pdf)
- [http/1.0、http/1.1、http/2、https](https://zhuanlan.zhihu.com/p/43787334)
- [http/1.x 的连接管理-MDN](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Connection_management_in_HTTP_1.x)
- [http/1.x 的缺点总结](https://segmentfault.com/a/1190000013519925)

#### 1.3 https(HyperText Transfer Protocol over SecureSocket Layer)
- SSL(secure socket lasyer, 安全套接层)/1.0: 1994年NetScape 公司设计，未发布；
- SSL/2.0: 1995年NetScape 公司发布，但存在严重漏洞；
- SSL/3.0: 1996年NetScape 公司发布，得到大规模应用；
- TLS(transport layer security, 安全层传输协议)/1.0: 1999年互联网标准化组织(ISOC)接替 NetScape 公司，发布SSL的升级版TLS/1.0；
- TLS/1.1: 2006年发布；
- TLS/1.2: 2008年发布；
- TLS/1.2修订版:2011年发布；
SSL/TLS 协议位于TCP/IP协议与各种应用层协议之间(表示层)，为数据通信提供安全支持。

HTTPS 可以说是安全版的 http, https 基于安全的SSL/TLS层，即在传统的HTTP和TCP之间加一层用于加密解密的SSL/TLS层。可以说HTTP加上加密处理、认证以及完整性保护后就是 HTTPS。 HTTP默认使用80端口，HTTPS默认使用443端口。

http 以及其他未加密的协议中都会出现的问题：
- 通信使用明文，内容可能会被窃听。
- 不验证通信方的身份，因此可能遭遇伪装。
- 无法证明报文的完整性，所以有可能已遭篡改。

SSL/TLS 协议是为了解决这三大风险而设计的，以期达到：
- 信息加密：第三方无法窃听。
- 校验机制：一旦被篡改，通信双方会立刻发现。
- 身份证书：防止身份被冒充。

##### 1.3.1 解决方案
SSL/TLS 的功能实现主要依赖于三类基本算法：散列函数、对称加密、非对称加密。利用非对称加密实现身份认证和密钥协商，对称加密算法采用协商的密钥对数据进行加密，基于散列函数验证信息的完整性。

1. 解决内容可能被窃听的问题 —— 加密

   对称加密：加密和解密用同一个密钥。使用对称加密时必须将密钥发送给对方，因此要确保密钥在转发途中的安全，另外还需要安全的保管收到的密钥。

   非对称加密：非对称加密使用一对非对称的密钥：公钥、私钥。私钥不能让其他任何人知道，公钥则可以随意发布，任何人都可以获得。

   非对称加密优点：
   - 使用非对称加密：发送方使用接收方的公钥进行加密，接收方收到信息后使用自己的私钥解密。这样不需发送用来解密的私钥，也不必担心密钥被攻击者窃听盗走。
   - 非对称加密可以一对多，服务器只需要维持一个私钥就能够和多个客户端进行加密通信。

   非对称加密缺点：
   - 公钥是公开的，所以针对私钥加密的信息，攻击者截获后可以使用公钥解密，获取其中的信息(理论上，公钥和私钥可以用任意一个加密，然后用另一个解密)。
   - 公钥中不包含服务器信息，使用非对称加密算法无法确保服务器身份的合法性，存在中间人攻击的风险，服务器发送给客户端的公钥可能在传送过程中就被中间人截获并篡改了。
   - 在数据加密解密过程中需要消耗一定时间，降低了传输效率。

   对称加密+非对称加密(https采用这样的方式)：
   使用对称加密的好处是解密的效率比较快，使用非对称加密的好处是传输的内容不能被破解。可以将二者结合起来，充分利用二者的优势，在交换密钥的阶段使用非对称加密的方式，之后的建立通信交换报文阶段则使用对称加密的方式。HTTPS 就采用这种对称加密和非对称加密并用的混合加密机制。

2. 解决报文可能遭篡改问题 —— 数字签名

   网络传输过程中需要经过很多中间节点，虽然数据无法被解密，但可能被篡改，需要通过校验数字签名来校验数据的完整性。

   数字签名有两种功效：
   - 能确定消息确实由发送方签名并发过来的。
   - 能确定消息的完整性，证明数据未被篡改过。

   数字签名的生成：将要发送的信息用 Hash 函数生成消息摘要，然后用发送方的私钥加密生成数字签名，与原信息一起传送给接收者。

   数字签名的校验：接收方使用发送方的公钥解密数字签名拿到摘要，再对收到的信息用Hash函数生成消息摘要，然后将两个摘要相对比。若相同，则说明收到的信息是完整的，在传输过程中没有被修改过。

   问题的关键在于，公钥如何安全的在网络中传送到客户端。此时就引入了证书颁发机构(Certificate Authority,简称CA),CA数量并不多，大多数操作系统CA证书是默认安装的。

3. 解决通信身份可能被伪装的问题 —— 数字证书
   数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。

   使用数字证书认证的流程：
   1. 服务器的运营人员向CA提交公钥、组织信息、个人信息(域名)等信息并申请认证。
   2. CA 通过线上、线下等多种手段验证申请者提供信息的真实性。
   3. 若信息审核通过，则 CA 会向申请者签发认证文件 —— 证书。证书包含：申请者公钥、申请者的组织和个人信息、签发机构CA的信息、有效时间、证书序列号等信息的明文。证书中同时还包含一个数字签名：使用散列函数计算明文信息的摘要，然后使用CA的私钥对摘要进行加密，得到数字签名。
   4. 客户端向服务器发出请求时，服务器返回证书文件。
   5. 客户端读取证书中的明文信息，并使用散列函数计算得到其摘要。然后，使用对应CA的公钥解密签名数据，对比证书的信息摘要，若一致，则可以确认证书的合法性，即服务器的公开密钥是值得信赖的。
   6. 客户端还会验证证书相关的域名信息、有效时间等信息。客户端内置了CA的证书信息(包含公钥)，若CA不被信任，则找不到对应的CA的证书，证书也会被判定非法。

4. https 工作流程
   1. SSL/TLS 四次握手(Client 和 Server 协商加密算法参数)，在TCP建立连接之后进行：
      - Client 发送 Client Hello 消息，其中包含支持的SSL版本，支持的加密算法，随机数(client random)等信息。
      - Server 发送 Server Hello 消息，其中包含SSL版本，加密的算法，服务器证书，随机数(server random)等信息。
      - Client 验证证书：是否有效，是否对应请求站点，它的上一级证书是否有效(递归，直到验证到根证书)。若验证有效则发送消息：使用公钥加密的随机数(premaster secret),编码改变通知(表示随后的信息都将通过双方商定的加密方法和密钥发送)，Client 握手结束通知(同时也是前面发送的所有内容的 hash 值，用来供服务器校验。   加密？握手协商是否能够成功，以服务器能否正确解密该报文作为标准——《图解HTTP》)。
      - Server 收到加密的随机数后，使用私钥解密，获取到该随机数。向客户端发送信息：编码改变通知，Server 握手结束通知。
      - Client 和 Server 根据约定的算法，使用前面三个随机数生成对称密钥(session key)，用来加密接下来的整个对话过程。

      SSL/TLS 完全握手需要至少两个RTT才能建立，简化握手需要1个RTT的握手延迟。TLS 协议层面也有一个队头阻塞，因为TLS协议都是按照 record 来处理数据的，将一堆数据放在一起(即一个 Record)加密，加密完后有拆分成多个TCP包传输。一般每个Record 16K, 包含 12 个TCP包，这样如果12个包中有任何一个包丢失，那么整个Record 都无法解密。
   2. SSL 连接建立完成，通信受到SSL保护，从此处开始进行应用层协议的通信，也就是发送HTTP请求。

生成对话密钥需要三个随机数，但前两个随机数都有被窃听、篡改的可能，所以整个通话的安全，只取决于第三个随机数能否被破解。前两个随机数存在的原因是 SSL 协议不信任每个主机都能产生完全随机的随机数，若随机数不随机，则 pre master secret 就有可能被猜出来；而 Client 和 Server 的随机数加上 pre master secret 三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能不够随机，但三个伪随机就十分接近随机了。

优点：
1. 数据传输的安全性(窃听无用)，数据完整，客户、服务器的身份认证。
2. 搜索引擎优先展示 https 结果。

缺点：
1. SSL 握手，加密、解密增加了延迟。
2. 加密、解密算法消耗 cpu 资源。
3. 证书申请需要额外的费用。

参考：
- [HTTP/1.0、HTTP/1.1、HTTP/2、HTTPS](https://zhuanlan.zhihu.com/p/43787334)
- [深入理解HTTPS工作原理](https://juejin.im/post/5ca6a109e51d4544e27e3048#heading-1)
- 《图解HTTP》
- [https 运行原理解析笔记](https://coolcao.com/2018/08/06/https/)
- [SSL/TLS 协议运行机制的概述](https://juejin.im/entry/5b91e519e51d450e4627f605)

#### 1.3 SPDY
SPDY(读作“SPeeDY”) 是 Google 开发的基于TCP 的会话层协议，用以最小化网络延迟、提升网络速度、优化用户的网络使用体验。它并不是一种用于替代HTTP的协议，而是对HTTP协议的增强。它的功能包括数据流的多路复用、请求优先级、HTTP 报头压缩。

IETF 对SPDY 协议进行了标准化，与 2015年5月推出了类似SPDY协议的HTTP2.0协议标准(http/2)，Google 因此宣布放弃对SPDY协议的支持，转而支持 HTTP/2。

#### 1.4 http/2
http/2 是一种安全高效的下一代 http 传输协议，安全是因为 http/2 建立在 https 协议的基础上，高效是因为它通过二进制分帧来进行数据传输。http/2 的设计本身允许非加密的http协议，但多数主流浏览器都声明只实现通过TLS加密的 http/2 协议，这使得经TLS加密的 http/2 成为了事实上的强制标准。

http/2 没有改动 http 的应用语义，http 方法、状态代码、URI 和 标头字段等核心概念一如往常。不过，http/2 修改了数据的格式(分帧)以及在客户端与服务器间传输的方式，这二者统领全局，并通过新的分帧层向应用隐藏了所有复杂性。因此，所有现有的应用都可以直接在新协议上运行。

##### 1.4.1 设计和技术目标
早期版本的 http 协议的设计初衷主要是实现简单，但这是以牺牲性能为代价的：
1. http/1.x 要使用多个连接才能实现并发和缩短延迟。
2. http/1.x 不会压缩请求和响应标头。
3. http/1.x 不支持有效的资源优先级，致使底层TCP连接的利用率底下等等。

随着网络应用的范围、复杂性以及重要性不断增加，这些限制对网络开发者和用户都造成了巨大负担，这正是 http/2 要致力于解决的：
1. http/2 支持在同一连接上进行多个并发交换，对同一连接上的请求和响应消息进行交错发送。
2. http/2 支持 header 字段压缩。
3. http/2 允许为请求设置优先级，让更重要的请求更快速地完成，从而进一步提升性能。
4. http/2 更有利于网络，因为它可以使用更少的TCP连接。
5. http/2 还可以通过使用二进制消息分帧对消息进行更高效的处理。

##### 1.4.2 二进制分帧层
http/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 http 消息并在客户端和服务器之间进行传送。这里的“层”指的是位于TCP与HTTP之间一个经过优化的新编码机制：http 的语义不受影响，不同的是传输期间对它们的编码方式变了。http/1.x 以换行符作为纯文本的分隔符，而 http/2 将所有传输的信息分分割为更小的消息和帧，并采用二进制格式对它们编码。因此，客户端和服务器为了相互理解，都必须使用新的二进制编码机制。
![http/2-frame](/Image/http2-frame.png)

##### 1.4.3 数据流、消息和帧：
新的二进制分帧机制改变了客户端与服务器之间交换数据的方式，首先明确三个概念：
- 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息(一对请求和响应？)。
- 消息：与逻辑请求或响应消息对应的完整的一系列帧。
- 帧：http/2 通信的最小单位。

这些概念的关系总结如下：
- 所有通信都在一个TCP连接上完成，此连接可以承载任意数量的双向数据流。
- 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。
- 每条消息都是一条逻辑 HTTP 消息(如请求或响应),包含一个或多个帧。
- 帧是最小的通信单位，承载着特定类型的数据(如http　header, 消息负载等等)，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。

简而言之，http/2 将 http 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 tcp 连接内复用。这是 http/2 协议所有其他功能和性能优化的基础。

在 http/1.x 中，要发起多个并行请求以提升性能，则必须使用多个TCP连接，该模型可以保证每个连接每次只交付一个响应(响应排队)，且这种模型也会出现队首阻塞。二进制分帧层则突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 http 消息分解为互不依赖的帧，然后交错发送，最后在另一端把他们重新组装起来。
![http2-请求和相应复用](/Image/http2-connection.png)

将http 消息分解为独立的帧，交错发送，然后在另一端重新组装是 http2 最重要的一项增强。事实上，这个机制可以带来巨大的性能提升,让我们可以：
- 并行交错地发送多个请求，请求之间互不影响。
- 并行加错地发送多个响应，响应之间互不影响。
- 使用一个连接发送多个请求和响应。
- 不必再为绕过 http/1.x 限制而做很多工作(如级联文件、image sprites 和域名分片)。
- 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间。
- ...

帧结构：
1. 所有帧都由一个固定的9字节头部跟一个指定长度的 payload 组成:
   - Length 3字节： 帧长度。
   - Type 1字节：帧类型。
   - Flags 1字节：为帧类型相关而预留的布尔标识，对于不同的帧类型赋予了不同的语义。
   - R 1位：保留的比特位。
   - Stream Identifier 31位。用作流控制，客户端建立的sid 必须为奇数，服务端建立的sid必须为偶数。值(0x0)保留给 SETTINGS 帧。
   - Payload:主体内容。

帧类型，共10种：
- HEADERS: 打开一个流或携带一个首部块片段。
- DATA: 主体信息。
- PRIORITY: 指定发送者建议的流优先级。
- RST_STREAM: 请求取消一个流，或者表示发生了一个错误。不能在处于空闲(idle)状态的流上发送RST_STREAM 帧。
- SETTINGS: 设置此连接的参数，作用于整个连接。
- PUSH_PROMISE: 服务端推送，客户端可以返回一个 RST_STREAM 帧来选择拒绝推送的流。
- PING: 判断一个空闲的连接是否可用，也可测量最小往返时间。
- GOAWAY: 用于发起关闭连接的请求，或警示严重错误。GOAWAY 会停止接收新的流，并在关闭连接前处理完先前建立的流。
- WINDOW_UPDATE: 执行流量控制，作用在流或整个连接上(sid为 0x0)。
- CONTINUATION: 继续传送首部块序列。

##### 1.4.4 数据流优先级：
将http 消息分解为很多独立的帧之后，客户端和服务器交错发送和传输这些帧的顺序也会影响到性能。为了决定顺序，http/2 允许每个数据流都有一个关联的权重和依赖关系：
- 可以向每个数据流分配一个１至256之间的整数。
- 每个数据流与其他数据流之间可以存在显示依赖关系。

数据流依赖关系和权重的组合让客户端可以构建和传递“优先级树”，表明它倾向于如何接收响应。服务器可以根据此信息通过控制CPU、内存和其他资源的分配设定数据流处理的优先级，在资源数据可用之后，带宽分配可以确保将高优先级响应以最优方式传输至客户端。

资源分配方式：
1. http2 中的数据流依赖关系通过将另一个数据流的唯一标识符作为父项引用进行声明，忽略的话则将依赖于“根数据流”。该依赖关系指出，应**尽可能**向父数据流分配资源，然后再向其依赖项分配资源。
2. 共享相同父项的数据流按其权重比例分配资源。

依赖关系和权重组合明确表达了资源优先级，这是一种用于提升浏览性能的关键功能，网络中拥有多种资源类型，它们的依赖关系和权重各不相同。且 http/2 还允许客户端随时更新这些优先级，进一步优化了浏览器性能。

需要注意的是：优先级并不是绝对的，只是尽可能，客户端无法强制服务器通过数据流优先级以特定顺序处理数据。否则可能存在高优先级资源受到阻止时，还阻止服务器处理优先级较低的资源的情况。

##### 1.4.５　每个来源一个连接：
有了新的分帧机制后，http/2 不再依赖多个TCP连接去并行复用数据流；每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别设定优先级。因此，http/2 连接是持续的，且一个 origin 仅需要一个连接，这带来了诸多的性能优势。

##### 1.4.6 流控制：
TCP 也有流量控制，但由于 http/2 数据流在一个TCP连接内复用，TCP流控制既不够精细，也无法提供必要的应用级API来调节各个数据流的传输。因此，http/2 提供了一组简单的构建块，这些构建块允许客户端和服务器实现其自己的数据流和连接级流控制：
- 具有方向性。接收方可以根据自身情况为每个数据流和整个连接设置任意的窗口大小。
- 建立 http/2 连接后，客户端与服务器交换 SETTINGS 帧，这会在两个方向上设置流量控制窗口(默认为 65535),接收方可以在收到任意数据时通过发送 WINDOW_UPDATE 帧来调整窗口大小。
- 流控制为逐跃点控制，而非端到端控制。
- TCP 通过头部中的字段滑动窗口，而这里只有 WINDOW_UPDATE 改变窗口大小。所以在没有收到WINDOW_UPDATE 时，发送窗口可用窗口会随着数据的发送减小，当接收方处理完部分数据接收窗口足够大时，会发送WINDOW_UPDATE 来更新窗口。

应用层流控制允许浏览器仅提取一部分特定资源，通过将数据流控制窗口减小为０来暂停提取，稍后再行恢复。

##### 1.4.7 服务器推送：
http/2 服务器推送是 http/2 新增的另一个强大功能，借此服务器可以对一个客户端请求发送多个响应，即除了对最初请求的响应外，服务器还可以向客户端推送额外的资源，而无需客户端明确地请求。

一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。而实际上服务器已经知道客户端下一步要请求什么资源，提前推送这些资源，可以减少额外的延迟时间。

事实上，在网页中内联 CSS, JS 或者通过数据URI内联其他资源等等将资源手动内联到文档的方式，实际上就是在将资源推送给客户端，而不是等待客户端请求。使用 http/2 不仅可以实现相同的结果，还会获得其他性能优势, 推送资源可以进行以下处理：
- 有客户端缓存。
- 在不同页面之间重用。
- 与其他资源一起复用。
- 有服务器设定优先级。
- 被客户端拒绝。

服务器推送特点：
1. 所有服务器推送数据流都由　PUSH_PROMISE 帧发起，表明了服务器向客户端推送所述资源的意图，且需要先于客户端请求的响应传输(以免客户但收到响应后对这些资源创建重复请求)。所以需要先于响应发送所有　PUSH_PROMISE 帧，其中包含所承诺资源的 http header。
2. 客户端收到　PUSH_PROMISE 帧后，可以选择拒绝数据流(通过 RST_STREAM 帧)，比如资源已经在缓存中的情况，这相对于 http/1.x 无法拒绝、取消的资源内联也是一个重要提升。
3. 客户端仍然完全掌控服务器推送的使用方式：可以限制并行的数据流数量，调整流控制窗口控制数据的推送量或完全停用服务器推送。
4. 推送的每个资源都是一个数据流，与内联资源不同，客户端可以对他们逐一复用、设定优先级和处理。浏览器的唯一安全限制是，推送的资源必须符合同源策略。

##### 1.4.8 header压缩(HPACK算法)：
每个 http 传输都携带了一组 header, 这些 header 说明了传输的资源及其属性。在 http/1.x 中，这些数据以存文本形式传送，通常给每个传输增加500~800字节的开销，若使用了 cookie, 则开销有时候会达到上千字节。为了减少此开销和提升性能，http/2 使用HPACK压缩传输的header。简单的说，HPACK 使用两个索引表来把头部映射到索引值：
1. 静态表： 预先定义好的，对于客户端和服务端都一样，目前包含61个键值。
2. 动态表： 动态表是一个由先进先出的队列维护的有空间限制的表，其中维护的是非静态表的索引。动态索引表需要双方维护，一个 http/2 连接有且仅有一份动态表。

存在索引空间之后，header 的字段一共有以下几种表示方法：
- 直接用索引值来表示。
- name 和 value 都用字符串表示，或其中之一用字符串表示。字符编码使用字节序列表示，要么直接使用字符的八位字节码要么使用哈夫曼编码。

参考：
- [深入理解 http2.0 协议，看这篇就够了](https://juejin.im/entry/5dba82c3e51d452a17370818)
- [http/2 简介](https://developers.google.com/web/fundamentals/performance/http2?hl=zh-cn)
- [http/2 详解](https://juejin.im/post/5b88a4f56fb9a01a0b31a67e#heading-62)
- [详解http-2头部压缩算法](https://segmentfault.com/a/1190000017011816)

#### 1.5 http/3
无论是SPDY还是http/2, 都是基于TCP的，TCP与UDP相比效率上存在天然的劣势(另一个原因在于继续在现有的TCP、TLS 协议之上实现一个全新的应用层协议，依赖于操作系统、中间设备还有用户的支持。部署成本非常高，阻力非常大)。2013年google开发了基于UDP的名为QUIC(Quick UDP Internet Connections)的传输层协议,希望它能替代TCP，使得网页传输更加高效。之后，IETF 正式将基于QUIC协议的HTTP重命名为HTTP/3。

UDP 与TCP 相比效率更高但不具备传输可靠性，而QUIC便是看中UDP传输效率这一特性，并结合了TCP、TLS、HTTP/2 的优势，加以优化：
![http/3-protocol](/Image/http3-protocal.png)

因此想要了解 http/3, 主要需要了解QUIC的主要特性：
##### 1.5.1 零RTT建立连接
http/2 的连接需要3RTT, 考虑会话复用(缓存第一次握手的对称密钥)，需要2RTT。若TLS升级到1.3，则http/2 连接需要2RTT, 考虑会话复用需要1RTT。

http/3 首次连接只需要1RTT, 后面的连接更是只需0RTT,意味这客户端发给服务器的第一个包就带有请求数据。QUCI的连接过程(DH密钥交换算法)：
1. 首次连接，Client 发送Inchoate Client Hello 给 Server, 用于请求连接。
2. Server 生成随机数g、p、a,根据他们算出A。然后将 g、p、A放到Server Config 中再发送Rejection 消息给Client。 
3. Client 收到 g、p、A 后，自己再生成b, 根据 g、p、b 算出 B, 根据 A、p、b 算出初始密钥K。然后Client 使用 K 加密 http 数据，连同B一起发送给服务端。
4. Server 收到B后，根据 a、p、B 生成与客户端相同的密钥，在用该密钥解密 HTTP 数据。为了进一步的安全(前向安全性)，Server 会更新自己的随机数 a和公钥，再生成新的密钥S, 然后把公钥通过Server Hello 发送给客户端。连同Server Hello 消息，还有HTTP 返回数据。
5. Client 收到 Server Hello 后，生成与Server 一样的新密钥，后面的传输都使用S加密。

因此，QUIC 从请求连接到正式接发HTTP数据一共花了1RTT，这1个RTT主要是为了获取Server Config, 后面的连接如果 Client 缓存了 Server Config, 那么就可以直接发送HTTP数据，实现0RTT建立连接。
![QUIC-DH-algorithm](/Image/DH-algorithm.png)
在密钥计算过程中，a 和 b 并不参与网络传输，安全性大大提高。而 p 和　g 是大数，即使　p、g、A、B 在传输中被劫持，那么靠现在的计算机算力也无法破解密钥。

##### 1.5.2 连接迁移
TCP连接基于四元组(源IP、源端口、目的IP、目的端口)，连接迁移指的是，当其中任何一个元素发生变化时，这条连接依然维持着，能够保持业务逻辑不中断。比如手机在 wifi 和 4G 切换时，客户端 IP 会发生变化，需要重建和服务器的TCP连接。

QUIC 做到连接迁移的原理在于QUIC 连接不再以IP及端口四元组标识，而是以一个64位的随机数作为ID来标识。这样即使IP或端口发生变化，只要ID不变，这条连接依然维持着，上层业务逻辑感知不到变化，不会中断，也就不需要重连。

##### 1.5.3 没有队头阻塞的多路复用
多路复用是 http/2 的一个强大特性，它基本上在http 层面上解决了 http/1.x 的队头阻塞问题。但它没能解决TCP的队头阻塞问题，不仅如此，它使得多个请求在一个TCP连接上发送出去，反而恶化了这个问题。

因为TCP要求按序到达，所以若是发送途中某个流的tcp segment 丢失了，则需要发送端重传该 tcp segment 才能通知应用层读取接下去的数据，即使后面其他流的数据已经到了接收端，也会被阻塞住。不仅如此，因为 http/2 强制使用 TLS，还存在一个TLS协议层面的队头阻塞。

QUIC 多路复用可以避免 http/2 的队头阻塞：
1. QUIC 最基本的传输单元是 Packet, 不会超过MTU的大小，整个加密过程都是基于Packet, 不会跨越多个 Packet,这样就能避免TLS协议存在的队头阻塞。
2. Stream 之间相互独立，比如 stream2 丢了一个 Packet, 不会影响 stream3 和 stream4, 不存在队头阻塞。

##### 1.5.4 拥塞控制
TCP 拥塞控制由4个核心算法组成：慢启动、拥塞避免、快重传和快恢复。QUIC 重新实现了TCP协议的Cubic 算法进行拥塞控制，并在此基础上做了不少改进：
1. 热插拔：TCP 中如果需要修改拥塞控制策略，需要在系统层面进行操作。QUIC 只需要在应用层操作，并且QUIC 会根据不同的网络环境、用户来动态选择拥塞控制算法。应用程序不需要停机和升级就能实现拥塞控制的变更，只需在服务器修改配置，然后 reload 即可。
2. 前向纠错 FEC: 增加协议的容错性。一段数据被分为数个包后，依次对每个包进行异或运算，得到FEC包一起传输。若某个包丢失，则可以根据剩余的包和EFC包推算丢失的包的数据。因为现阶段网络传输的瓶颈不是带宽而是往返时间，所以可以适当增加数据冗余，减少重传操作。
3. 单调递增的 Packet Number: TCP 使用序列号和ACK来确认消息是否到达，这导致发生重传时无法测量往返时间。因此Packet Number 与序列号不同，它严格递增，发送方就可以轻松的判断确认是针对哪一个发送的消息。

   单纯依靠严格递增的 Packet Number 肯定无法保证数据的顺序性和可靠性。QUIC 又引入了 Stream Offset 的概念： 一个Stream 可以经过多个 packet 传输，依靠 Stream 的 Offset 来保证应用数据的顺序(即重传的 packet 中 Stream Offset 不变)。

4. ACK Delay: TCP 计算RTT时没有考虑接收方收到数据发送ACK 之间的延迟(ACK Delay)。QUIC 考虑了这段延迟，使得RTT计算更加准确。

5. 更多的ACK 块：TCP SACK 最多在接收到3个ACK block, 而QUIC 可以携带256。在网络丢包严重时，可以减少重传，提升效率。

##### 1.5.5 流量控制
QUIC 的流量控制类似于 HTTP2, 即在 Connection 与 Stream 级别提供了两种流量控制，QUIC 实现流量控制原理：
- 通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。
- 通过BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。

TCP 为了保证可靠性，窗口左沿的滑动取决于已经确认的字节数，而QUIC 就算此前有些packet 没有收到，它的滑动也只取决于最大偏移字段(重传的packet number 不同，滑动时根据SACK 保留了部分数据?)。

可用窗口：
- 针对 Stream: `可用窗口 = 窗口值 - 接收到的最大偏移值`
- 针对 Connetion: `可用窗口 = stream1 可用窗口 + stream2 可用窗口 + ...`

参考：
- [http/3 原理实战](https://zhuanlan.zhihu.com/p/143464334)
- [科普：QUIC协议原理分析](https://zhuanlan.zhihu.com/p/32553477)
- [一文读懂 http/1 http/2 http/3](https://zhuanlan.zhihu.com/p/102561034)
- [http/3 原理与实践](http://www.alloyteam.com/2020/05/14385/)
