***
### 1. 分层

OSI 7层和 TCP/IP 5层：
![network layoer](/Image/networkLayer.png)

从一般概念上讲，计算机或网络互连要使用一些中间设备：
- 物理层 —— 转发器
- 数据链路层 —— 网桥或桥接器
- 网络层 —— 路由器
- 网络层以上 —— 网关
转发器和网桥仅仅是把一个网络扩大了，路由器连接网络。

### 2 物理层
1. 为设备之间的数据通信提供传输媒体(电缆、光纤、无线信道)及互连设备。
2. 传输数据(比特流(0, 1)信号)。
### 3 数据链路层
要在一条线路上传递数据，除了必须有一条物理线路外，还必须有一些通信协议来控制这些数据的传输，若把这些实现协议的软件硬件加到物理链路上，就构成了数据链路。

主要功能(为网络层提供数据传送服务)：
1. 封装成帧(frame)：接收端能够从物理层上交的比特流中根据首尾部标记识别出帧，并取出数据
2. 透明传输：无论什么样的比特组合都能够通过，对首尾标识以及转义字符的转义
3. 差错检测：比特在传输过程中可能出错(循环冗余检验)：
    - 在通信质量良好的有线链路，数据链路层丢弃错误帧，即只保证接收的帧无差错，确认和重传由上层协议来完成。(帧比较小，正确率高的情况下每一帧都要确认比较耗费资源)
    - 在通信质量差的无线链路，数据链路层使用确认和重传机制，向上提供可靠传输的服务。(正确率低时，上层数据报频繁重发会使得很多成功发送的帧重发)

数据链路层最常见的独立产品是网卡(计算机MAC地址)，网桥(根据MAC帧的目的地址对收到的帧进行转发和过滤)。

数据链路层的信道主要分为：
1. 点对点信道，PPP协议
2. 广播信道，CSMA/CD协议(以太网)

### 4 网络层
发送数据时，网络层负责把运输层产生的报文段或用户数据报封装成`IP数据报(datagram)`进行传送；另一个任务是选择合适的路由，使得IP数据报能够通过网络中的路由器找到目的主机(也就是路由或寻径)。

网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务，所传送的分组可能出错、丢失、重复和失序。

##### 4.1 网际协议IP
网际协议IP是作用是使互连起来的许多计算机网络之间能够进行通信，与之配套使用的还有ARP,ICMP,IGMP。

IP协议可以使各个性能各异的网络在网络层看起来像是一个同一个网络。

IP地址特点：
- IP地址一般有两个部分组成：网络号和主机号。A类、B类和C类地址的区分已成为历史。
- IP地址是32位的二进制代码，为提高可读性，使用点分十进制记法。
- 网络号全0 表示“本网络”，主机号全0表示“本主机”；网络号为 127 保留作为本地软件环回测试本主机的进程之间的通信只用，主机号全 1 表示该网络上的所有主机。B类C类不会出现网络号全为0或1的情况。
- 一个网络指具有相同网络号的主机的集合，因此用转发器或网桥连接起来的若干个局域网仍为一个网络。路由器每一个接口都有一个不同网络号的IP地址(路由器直连时可能不会分配IP地址)。

IP地址与硬件地址(物理地址、MAC地址)：
- 硬件地址是数据链路层和物理层使用的地址，IP地址是网络层及以上使用的地址，是一种逻辑地址。
- 使用IP地址(首部中)的IP数据报在数据链路层被封装成MAC帧，MAC帧在传送时使用的源地址和目的地址都是硬件地址(MAC帧首部中)。
- 在路由器中转发时，IP数据报首部中的源地址和目的地址始终都不会变化，而MAC帧首部中的源地址和目的地址都要发生变化。

网络层抽象的互联网屏蔽了下层复杂的细节，使我们得在网络层上讨论问题时，能够使用统一的、抽象的IP地址研究主机和主机或路由器之间的通信。

###### 4.1.2 ARP
ARP解决的是(同一个局域网上)已知一个机器(主机或路由器)的IP地址，需要找出其相应的硬件地址的问题。

网络层使用的是IP地址，但实际在网络的链路上传送数据帧时，还是必须使用网络的硬件地址。但IP地址和MAC地址由于格式不同而没有简单的映射关系，且主机的加入、撤走，更换网卡都可能导致MAC地址改变。ARP的解决办法就是在主机(路由器)ARP高速缓存中存放本局域网上各主机从IP地址到MAC地址的映射表，且该表经常动态更新(新增或超时删除)。

ARP特点：
- 当一个主机向另一个主机发送数据时，若在映射表中找不到目的主机的IP地址项目，则源主机自动运行ARP,ARP进程在局域网广播发送一个APR请求分组，对应的主机会以单播的形式响应分组。
- ARP把映射表中的每一个项目都设置生存时间，超过生存时间的就删除。
- 从IP地址到硬件地址的解析是自动进行的，主机用户对这种地址解析过程并不知情。只要主机要和本网络上的一个已知IP地址的主机或路由器进行通信，ARP协议就会自动将IP地址解析为MAC地址。

###### 4.1.3 IP数据报格式
IP数据报由首部和数据两部分组成。首部分固定首部和可选字段。固定首部中包含了版本、首部长度、总长度、标识、标志、片偏移、生存时间、协议、首部校验和等字段。

IP数据报分片(一个IP数据报分成多个IP数据报)：
- 总长度字段为 16 位，因此数据报最大长度为 2^16 - 1 字节。而每一种数据链路层协议都规定了一个数据帧中数据字段的最大长度，这称为MTU。若传送的IP数据报长度超过MTU,就必须把过长的数据报进行分片处理。
- 虽然IP数据报越长，传输效率越高(分片少，首部长度占总长度比例小)；但IP数据报越短，路由器转发速度越快。因此IP协议规定路由器和主机必须能接受长度不超过576字节的数据报；若超过，则需要先了解目的主机能否接受该长度，不能就要分片。
- 标识在数据报分片时，会被复制到所有数据报片的标识字段，使得各分片最后能正确重装为原来的数据报。
- 标志占3位，目前两位有意义。最低位记为MF,MF为1表示后面还有分片；MF为0表示已经是分片中的最后一个。中间一位记为DF,DF为1表示不能分片；DF为0表示允许分片。
- 片偏移表示某片在原分组中的相对位置，既相对数据字段的起点。片偏移以8字节为偏移单位，所以每个分片一定是8字节(64位)的整数倍。
- 生存时间TTL，占8位 目的是防止无法交付的数据报无限制的在因特网中兜圈子。TTL 从时间限制(技术进步，路由器处理数据报所需时间不短缩短)改为跳数限制，路由器转发之前将TTL(最大255)减1,若为0 就丢弃。

首部的可选字段增加了路由器处理数据报的开销，而很少被使用，因此IPv6把IP数据报的首部长度做成固定的。

###### 4.1.4 IP层转发分组流程
按照主机号来制作路由表会导致路由表过于庞大，所以按照网络地址来制作。路由表每一行最主要的是目的主机所在网络和下一跳地址，若不需再经过路由器，则可通过接口直接交付(路由器中有ARP映射表)。

其他路由：
- 因特网中所有的分组转发都是基于目的主机坐在网络，但允许有这样的特例：对特定的目的主机指明一个路由，叫做特定主机路由。可使网络管理人员能更方便的控制网络和测试网络，或用在考虑某种安全问题的情况下。
- 路由器可以采用默认路由来减少路由表所占用的空间和搜索路由表所用的时间。这种方式在一个网络只有很少的对外连接时很有用。

分组转发算法：
1. 从数据报首部提取目的主机的IP地址D，得出网络地址N。
2. 若N与路由器直接相连，则直接交付；否则3。
3. 若路由表中有D的特定主机路由，则把数据报传送给路由表中指明的下一跳路由；否则4。
4. 若路由表中有到达N的路由，则把数据报传送给路由表中指明的下一跳路由；否则5。
5. 若路由表中有默认路由，则把数据报传送给路由表中指明默认路由器；否则6。
6. 报告转发分组出错。

##### 4.2 划分子网
两级IP地址缺点：
1. 网络地址利用率低。
2. 给每一个物理网络分配一个网络号会使得路由表变得太大(存储空间、查找时间、定期交换的路由信息急剧增加)，而使网络性能变坏。
3. 两级地址不够灵活，开通一个新的网络必须申请到一个新的IP地址。

为了解决两级IP的缺点，在IP地址中又增加了一个“子网段号”，将两级IP地址变成三级IP地址，这就是划分子网。

划分子网思路是：从网络的主机号借用若干位作为子网号，因此即使分配了多个子网，对外依然表现为一个网络。而与网络连接的路由器在收到IP数据报后，再按目的网络号和子网号找到目的子网，把IP数据报交付目的主机。
###### 4.2.1 子网掩码
从IP数据报的首部无法看出源主机或目的主机所连接的网络是否进行了子网划分，因此需要**子网掩码**：
子网掩码也是32位，由一串1(对应网络号和子网号)跟随一串0(对应主机号)组成。

使用子网掩码的好处是：无论网络有无子网，只要把IP地址和子网掩码逐位“与”，就可以立即得到网络地址，路由器可以对到来的分组统一处理。为了便于查找路由表，规定所有的网络都必须使用子网掩码，路由表中也必须有子网掩码这一栏；路由器在和相邻路由器交换信息时(链路层广播?)，也必须把自己所在网络的子网掩码带上。若网络不划分子网，则其子网掩码就是**默认子网掩码**(一串1正好和网络号对应)

使用子网划分后，路由表必须包含：目的网络地址、子网掩码、下一跳地址三项。这时的分组转发算法与**1.3.4**中分组转发类似,只是不再需要网络地址N,并将交付或转发的条件变成检查 “子网掩码和IP地址逐位‘与’的结果与目的网络地址是否匹配”。

##### 4.3 无分类编制CIDR(构成超网)
划分子网在缓解了因特网在发展中遇到的困难，但依然有三个必须尽早解决的问题：
1. 网络地址不够，B类地址即将分配完毕。
2. 因特网主干上的路由表项目数量急剧增长。
3. 整个IPv4 地址空间终即将全部耗尽。
其中问题1、2迫在眉睫，IETF 研究出采用**无分类编制**
的方法来解决他们。该方法的正式名字为**无分类域间路由选择CIDR**,它最主要的特点有两个：
1. 消除了A类、B类和C类地址及划分子网(CIDR 不使用子网是指没有在32位中指明若干位作为子网字段，但分配到一个CIDR地址块的单位依然可以在内部根据需要划分出一些子网)的概念。CIDR把32为的IP分为两个部分。IP地址 ::= {<网络前缀>，<主机号>}。CIDR还使用斜线记法，即在IP地址后面加上斜线"/",然后写上网络前缀所占的位数。
2. CIDR把网络前缀都相同的连续的IP地址组成一个CIDR地址块。CIDR使用32位的**地址掩码**，其中1的个数就是网络前缀的长度，CIDR使用的地址掩码也可以继续称为子网掩码。

一个CIDR地址块中有很多地址，在路由表中利用CIDR地址块来查找目的网络，这种地址的聚合常称为**路由聚合**，它使得路由表中的一个项目可以表示原来传统分类地址的很多个路由。路由聚合也称为**构成超网**。CIDR的另一个好处是可以更加有效的分配IPv4的地址空间，而分类地址则只能分配A类、B类和C类。

使用构成超网后的路由匹配特点:
1. 最长匹配前缀
   
   路由表中项目主要由网络前缀、地址掩码和吓一跳地址组成。在查找路由表是可能会得到不止一个匹配结果，这时就应当从匹配结果中选择具有最长网络前缀的路由。
2. 使用二叉线索查找路由表
   
   由于要寻找最长匹配前缀，路由表的查找过程变得更加复杂。为了更加有效的查找，通常是把路由表存放在一种层次的数据结构中，然后自上而下的按层次进行查找。这里最常用的就是**二叉线索**，其每一个叶节点代表一个唯一前缀。二叉线索只是提供了一种可以快速在路由表中找到匹配的叶节点的机制，还需要和子网掩码进行逻辑与运算来确定是否和网络前缀比配。

##### 4.4 网际控制报文协议ICMP
为了更有效地转发IP数据报和提高交付成功的机会，在网际层使用了ICMP,它允许主机或路由器报告差错情况和提供有关异常情况的报告。虽然ICMP报文装在IP数据报中，作为其中的数据部分，但ICMP不是高层协议。

ICMP报文的种类有两种：
1. ICMP 差错报告报文
   - 终点不可达
   - 原点抑制
   - 时间超过
   - 参数问题
   - 改变路由(重定向)：主机不和连接在网络上的路由器定期交换路由信息，而是发送数据报到默认路由器；若重定向，则主机修改路由表。
2. ICMP询问报文
   - 回送请求或回答。 一个重要应用是分组网间探测PING,用来测试两个主机之间的连通性。PING是应用层直接使用网络层ICMP的一个例子，没有通过运输层的TCP或UDP。另一个非常有用的应用是traceroute,用来跟踪一个分组从源点到终点的路径。
   - 时间戳请求或回答。可用来进行时钟同步伐和测量时间。

##### 4.5 因特网路由选择协议
##### 4.6 IP多播

### 5 运输层
运输层负责向两个主机的进程之间的通信提供**通用**的数据传输服务。网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信；此外，运输层还要对收到的报文进行差错检测。

通用：多个应用可以使用同一个运输层服务，而一台主机可以同时运行多个进程，因此运输层有**复用**和**分用**的功能。复用指多个应用进程，分用则指运输层在剥去报文的首部后能够把这些数据正确交付目的相应进程。

主要使用协议：
- 传输控制协议TCP(Transmission Control Protocol): 提供面向连接的、可靠的数据传输服务，数据传输单位指TCP报文段(segment);其逻辑通信信道相当于一条全双工的可靠信道。
- 用户数据报协议UDP(User Datagram Protocol): 提供无连接的，尽最大努力的数据传输服务，数据传输的单位是UDP用户数据报;其逻辑通信信道仍然是一条不可靠信道。

##### 5.1 运输层的端口
要实现运输层的复用和分用，则给应用层每个应用进程赋予一个非常明确的标志是至关重要的。虽然单个计算机中的进程有进程标识符(进程ID)来标志，但不同操作系统使用的进程标识符不同。而为了运行在不同操作系统上的进程能够互相通信，必须使用统一的方法对TCP/IP体系的应用进程进行标志。

但是，进程的创建和撤销都是动态的，通信的一方几乎无法识别对方机器上的进程，因此把特定机器上的特定进程指明为因特网上通信的最后终点还是不可行的。解决这个问题的办法就是在运输层使用**协议端口号**,即我们只要把要传送的报文交到目的主机的某一个合适的端口，剩下的工作(最后交付到目的进程)就由TCP 来完成。

端口特点：
1. 这种在协议层间的抽象的协议端口是软件端口，与硬件端口(不同硬件设备进行交互的接口)是完全不同的概念，它是应用层的各种协议进程与运输实体进行层间交互的一种地址。
2. 因特网上的计算机通信是采用客户-服务器方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号，而客户端进程也会在报文中带上自己的端口号。
3. 运输层的端口号分为两大类：
   1. 服务器端使用的端口号，还可以分为两类：
      - 熟知端口号(well-known port number), 数值为 0 ~ 1023。这些数值可以在网上查到，这些端口号被指派给了TCP/IP相对重要的一些应用程序，所有用户都可以知道。当一个新的应用程序出现后，必须为其指派一个熟知端口，否则因特网上其他应用进程无法和它进行通信。
      - 登记端口号。数值为 1024 ~ 49151。这类端口号是为没有熟知端口号的应用程序使用的，使用这类端口号必须在IANA登记，以防止重复。
   2. 客户端使用的端口号。数值为 49152 ~ 65535，这类端口号仅在客户端进程运行时才动态选择，因此又叫短暂端口号。

##### 5.2 用户数据报协议UDP
UDP 只在IP的数据报服务之上增加了很少一点功能：复用、分用以及差错检测。UDP的主要特点为：
1. 无连接：减少了开销和发送数据之前的时延。
2. 尽最大努力交付。
3. 面向报文：对应用层交下来的报文，既不合并，也不拆分；而是保留边界，在添加首部后就交付IP层，因此应用程序必须选择合适大小的报文，否则由IP层分片，降低IP层效率；反之，报文短则导致IP数据报首部相对长度太大，降低IP层效率。
4. 无拥塞控制：对某些实时应用很重要，也可能引起网络产生严重的拥塞问题。
5. 支持一对一、一对多、多对一和多对多的交互通信。
6. 首部开销小，8个字节(TCP 20字节)。

UPD首部由四个字段组成：
1. 源端口。
2. 目的端口。
3. 长度(首部加数据)。
4. 检验和(12字节的伪首部)。

##### 5.3 传输控制协议TCP
TCP 协议比较复杂，它最主要的特点是：
1. 面向连接：使用之前，必须建立连接；传送结束后，必须释放连接。
2. 只能点对点(一对一)。
3. 可靠交付：无差错、不丢失、不重复、按序到达。
4. 全双工通信：应用进程在任何时候都能发送数据(TCP连接的两端都设有发送缓存和接收缓存)。
5. 面向字节流：
   - 虽然TCP 与应用程序的交互是一次一个数据块，但TCP仅将其看成是一连串的无结构字节流，TCP不保证应用程序发送的和对方收到的数据块具有对应大小关系，但其字节流是完全相同的。
   - TCP不关心应用进程一次发送多长的报文到缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少字节(划分或积累)。
6. TCP 连接的两个端点不是应用进程，也不是协议端口，而是套接字：套接字 socket = (IP地址：端口号)。这里的 socket 与应用编程接口API(socket API)不同。

##### 5.4 可靠传输的工作原理
理想的传输条件有两个特点：
1. 传输信道不产生差错。
2. 无论发送方发送数据多快，接收方总是来得及处理。

实际网络不直接具备这样的条件，但可以使用一些可靠传输协议，使得：
1. 出错重传。
2. 接收方来不及处理收到的数据时，及时告诉发送方适当降低发送速度。
###### 5.4.1 停止等待协议
主要讨论可靠传输原理，因此把传送的数据单元称为分组。

停止等待就是每发送完一个分组就停止发送，等待对方确认；收到确认后，再发送下一个分组：
1. 发送方每发送完一个分组，就设置一个超时计时器。
2. 发送方只要超过设置的时间没有收到确认，就认为分组丢失，重传分组，这就是**超时重传**；若收到确认，则撤销超时计时器：
   - 发送方发送完分组，必须保留副本(超时重传用)，收到确认后再清除。
   - 分组和确认分组都必须进行编号。
   - 超时计时器的重传时间应该比分组传输的平均往返时间更长一些。
3. 在确认丢失和确认迟到的情况下，发送方都会重发分组，而接收方应该丢弃分组并重新发送确认。
像这样的可靠传输协议通常称为 **自动重传请求ARQ**

信道利用率：发送分组时间<sub>TD</sub>, 发送确认时间 T<sub>A</sub>, 分组往返时间RTT，则利用率 U = T<sub>D</sub>/(T<sub>D</sub> + RTT + T<sub>A</sub>),而发送分组时间T<sub>D</sub>中再扣除分组等控制信息则利用率更小。因此可以看出，停止等待协议的优点是简单，缺点是信道利用率太低。为了提高传输效率，可以采用流水线传输，即发送方可以连续发送多个分组，而不是每发送一个就停下来等待确认。

使用流水线传输时，就要使用连续ARQ协议和滑动窗口协议。

###### 5.4.2 连续ARQ协议
连续ARQ协议通常结合滑动窗口协议使用，发送方会维持一个发送窗口：
1. 位于发送窗口内的分组可以按照序号从小到大连续发送出去，而不需等待确认，提高信道利用率。
2. 接收方一般采用**累积确认**的方式:不必对分组逐个发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认：
   - 优点：容易实现，即使确认丢失也不必重传(丢失确认的分组 之后的 分组确认 收到了？)。
   - 缺点：不能向发送方反映出接收方已经正确收到的所有分组信息(回退N，通信线路质量不好时，带来负面影响)。

##### 5.5 TCP 报文段首部格式
一个TCP报文段分为首部和数据两部分，其首部的前 20 个字节是固定的，后面有 4n 字节根据需要增加。
首部固定部分字段：
1. 源端口和目的端口： 各占2字节。
3. 序号：
   - 4字节。范围：[0, 2^32 - 1]，达到最大值后又回到0，即 序号使用 mod 2^32 运算。
   - TCP 是面向字节流的，在其中传送的字节流中的每一个字节都按顺序编号。首部中的序号字段值指本报文段所发送的数据的第一个字节的序号。
4. 确认号：4字节。是期望收到对方下一个报文段的第一个字节的序号，因此确认号为 N 表示到序号 N - 1 为止的所有数据都已经正确收到。
5. 数据偏移：占4位。 指出TCP报文段数据起始处距离TCP报文段的起始处有多远，实际就是首部长度。该字段的单位是 32位字(4字节)，4位二进制能表示最大十进制位 15,因此首部最大长度为 60字节。
6. 保留：占6位，保留为今后使用。
7. 紧急URG: 当 URG=1 时，表明紧急指针字段有效。它告诉系统报文中有紧急数据，应尽快传送(相当于高优先级的数据)，而不是按原来的排队顺序传送。这种情况下，发送方TCP一般会把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。
8. 确认ACK: 仅当 ACK=1 时确认号字段才有效。TCP规定，连接建立后所有传送的报文段都必须把ACK置1。
9. 推送PSH: 有时一端的应用进程希望在键入一个命令后立即能够收到对方的响应，这时就可以使用 PSH。发送发TCP把PSH置1，并立即创建一个报文段发送出去，接收方TCP收到PSH=1的报文段，就尽快地交付应用进程(不再等待缓存填满)。接收方是否使用将PSH置1来响应，则属于业务逻辑。
10. 复位RST: 当RST=1 时，表明TCP连接中出现严重差错(主机崩溃或其他原因)，必须释放连接，然后再重新建立运输连接。该字段置1也用来拒绝一个非法的报文段或拒绝打开一个连接。
11. 同步SYN: 在建立连接时用来同步序号。SYN 置 1 表示这是一个连接请求或连接接受报文。
12. 终止FIN: 用来释放一个连接。FIN=1 表示此报文段的发送方的数据已经发送完毕，要求释放运输连接。
13. 窗口： 2字节。指发送此报文段的一方的接收窗口。窗口值告诉对方：从此报文段首部中的确认号算起，接收方目前允许对方发送的数据量。有这个限制是因为接收方的数据缓存空间有限，总之,**窗口值作为接收方让发送方设置其发送窗口的依据， 且窗口值经常动态变化**。
14. 检验和：2字节。检验范围包括首部和数据，计算时，和UDP同样要添加伪首部，区别在于：需要把第4和5个字段分别改为TCP的协议号和TCP长度。
15. 紧急指针：2字节。仅在URG=1 时才有意义，指出了此报文段中紧急数据的字节数(紧急数据结束后就是普通数据)。即使窗口为0时也可发送紧急数据。
16. 选项：长度可变，最长 40 字节。
    - 最大报文段长度MSS：每一个TCP 报文段中的数据字段的最大长度。太小则网络利用率低，太大则IP层需要分片重组，出错时还要重传，也会使开销增大。所以在IP层不分片的条件下，MSS应该尽可能大。但路径不同，情况不同，最佳MSS 很难确定，所以由传送方将自己能够支持的MSS写入这一字段，默认为 536字节。
    - 窗口扩大：3字节。 对于包含卫星信道的网络，传播时延和带宽都很大，要获得高吞吐率需要更大的窗口大小。窗口扩大选项中一个字节表示**移位值S**, 新窗口值就等于 16 + S, S允许使用的最大值是 14。
    - 时间戳选项：10 字节。其中最主要的字段是**时间戳值**字段(4字节)和**时间戳回送回答字段**(4字节)。该选项有两个功能：计算往返时间RTT和处理TCP序号超过 2^32 的情况。

##### 5.6 TCP 可靠传输的实现
###### 5.6.1 以字节为单位的滑动窗口
TCP 的滑动窗口以字节为单位

发送窗口特点：
1. 发送方根据确认报文段的窗口和确认号构造出自己的发送窗口。虽然发送窗口由接收窗口设置，但在同一时刻，发送窗口并不总和接收窗口一样大，因为网络传送窗口值需要经历一定的时间滞后。
2. 发送方在没有收到接收方的确认的情况下，可以连续把窗口内的数据都发送出去。显然，窗口越大，就可能获得更高的传输效率，但接收方必须来得及处理这些收到的数据。
3. 已经发送过的数据，收到确认之前都必须暂时保留，留待超时重传。
4. 发送窗口的位置由窗口前沿("前"移指移向未发送的数据的方向)和后沿的位置共同确定。
   
   后沿变化情况两种：不动(未收到新的确认) 和 前移(收到新的确认)。
   
   前沿通常不断向前移动，在两种情况下不动：未收到新的确认 和 收到新的确认但对方通知窗口变小，使得发送窗口正好不动。前沿也可能向后收缩，但TCP的标准强烈不赞成这样做，因为窗口中的数据可能已经发送了很多，若又收缩窗口不让发送，则可能会产生一些错误。
5. 描述一个发送窗口的状态需要 3 个指针 p1(已发送但未收到确认)，p2(允许发送但尚未发送)，p3(不允许发送)。(因为拥塞控制，所以可能不是一次发完，所以存在p2?)
6. 发送方在收到确认后，就把p1移到对应的确认号，p2不动，p3由确认报文中的确认号和窗口值确定。
7. 发送方在发送完发送窗口中的数据后，p2向前移动和p3重合。而又没有再收到确认号，由于发送窗口已满、可用窗口为0，因此必须停止发送。为了保证可靠传输，发送方在经过一段时间后(超时计时器控制)就重传这部分数据，并重置超时计时器，直到收到确认。

缓存和窗口是有关系的，缓存空间和序号空间都是有限的，且都是循环使用的。

发送缓存和发送窗口：
1. 发送缓存用来暂时存放：
   - 发送应用程序传送给发送方TCP准备发送的数据。
   - TCP已经发送但未收到确认的数据。
2. 发送窗口通常只是发送缓存的一部分，已被确认的数据应当从缓存中删除，因此发送缓存和发送窗口的后延是重合的。且发送应用程序必须控制写入缓存的速率，不能太快，否则发送缓存就会没有存放数据的空间。

接收缓存和接收窗口：
1. 接收缓存用来暂时存放：
   - 按序到达，但尚未被接收应用程序读取的数据。
   - 未按序到达的数据。
2. 对于不按序到达的数据处理，TCP 标志并无明确规定。若丢弃，则接收窗口的管理简单，但对网络资源的利用不利。因此TCP通常对不按序到达的数据先临时存放在接收窗口，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。
3. TCP 要求接收方必须有累积确认的功能，以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据发送时把确认信息顺便带上。有两点需要注意：
   - 接收方不应过分推迟发送确认，否则会导致发送方不必要的重传。若收到一连串具有最大长度的报文段，则必须每隔一个报文段就要发送一个确认。
   - 捎带确认不常发生，因为大多应用程序不会同时在两个方向上传送数据。

##### 5.6.2 超时重传时间的选择
TCP下层的互联网环境复杂，每个IP数据报选择的路由还可能不同。若把超时重传时间设置的太短，则会引起很多不必要的重传，使网络负荷增大；若设置得太长，则又使网络的空闲时间增大，降低运输效率。
TCP 采用了一种自适应算法：
1. 报文段的往返时间 RTT：报文段发出的时间与收到相应确认的时间之差。
2. 加权平均往返时间 RTT<sub>S</sub>：s为smoothed。第一次测量到 RTT 时，RTT<sub>S</sub> 值就取为该 RTT 值，之后则为：新的Rtt<sub>S</sub> = (1 - α) * 旧的Rtt<sub>S</sub> + α * 新的RTT，推荐 α 为 1/8(0.125)。
3. 超时计时器设置的**超时重传时间 RTO**应该略大于 RTT<sub>S</sub>: RTO = RTT<sub>S</sub> + 4 * RTT<sub>D</sub>。
4. RTT<sub>D</sub>是RTT的偏差的加权平均值：第一次测量时，RTT<sub>D</sub>值为测量到的RTT值的一半，之后则为：新的RTT<sub>D</sub> = (1 - β) * 旧的RTT<sub>D</sub> + β * |RTT<sub>S</sub> - 新的RTT|，推荐 β 的值为 1/4(0.25)。
5. 但对于往返时间的测量，还十分复杂。因为若主机重传了数据报，则由于重传的数据报与原来的报文段完全一样，因此主机收到确认后无法做出正确的判断。Karn 提出了一个算法：只要报文段重传了，就不采用其往返时间样本。但这样做的问题在于：若报文段的时延突然增大了很多，在之前的重传时间内，无法收到确认报文段，因此需要重传。但若不考虑重传时的往返时间样本，则RTO就无法更新。因此对Karn算法的修正是：报文段每重传一次，就把RTO增大一些，典型的做法是设为之前的2倍。当不再发生重传时，则继续使用之前的算法。

##### 5.6.3 选择确认SACK
若收到的报文段无差错，而只是未按序到达，中间还缺少一些序号的数据。那么是否能只传送缺少的数据而不重传已经到达的数据呢，选择确认是一种可行的处理方法。

若要使用SACK,则建立连接时，就要在TCP的首部选项加上允许SACK的选项。在之后的TCP报文段的首部中都增加了SACK选项，以报告收到的不连续的字节块的边界。而首部选项的长度最大为 40 字节，一个边界4字节(序号32位)，另外还需要一个字节指明SACK选项，一个字节指明该选项要占用多少字节，因此选项中最多只能指明4个字节块的边界信息。SACK文档未指明发送方应当怎样响应SACK,因此大多数的实现还是重传所有未被确认的数据块。

#### 5.7 TCP 的流量控制
##### 5.7.1 利用滑动窗口实现流量控制
所谓流量控制就是让发送方发送速率不要太快，要让接收方来得及接收。利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。

接收方通过确认报文段中的ACK,ack以及rwnd(receiver window) 便可以控制发送方的发送窗口大小从而实现流量控制。

需要注意的是若 rwnd 为0,则发送方会暂停发送直到接收方重新发出一个不为0的 rwnd为止。但有可能更新 rwnd 的报文段在传送时丢失，则发送方等待接收方更新发送窗口，而接收方等待发送方发送数据，没有其他措施的情况下，这种死锁局面将一直持续下去。因此TCP为每一个连接设有一个持续计时器，只要发送方接收到 rwnd 为0的确认报文段，就启动该计时器，时间到期就发送一个探测报文段，接收方在确认该报文段时会给出当前窗口值。

##### 5.7.2 考虑传输效率
应用进程将数据传送到TCP缓存后，发送任务由TCP来控制，可以用不同的机制来控制TCP报文段的发送时机，如：
1. TCP维持一个变量，其值为MSS, 只要缓存中的数据到达最大报文段长度MSS,就组装成一个TCP报文段发送出去。
2. 有应用进程指明要求发送报文段(PSH)。
3. 发送方的计时器到期，将已有的缓存数据装入报文段(长度小于MSS)发送出去。

在TCP的实现中广泛使用Nagle算法：
1. 若应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，缓存后面到达的数据字节。
2. 当发送方收到对第一个数据字节的确认后，再把缓存中的数据组装成一个报文段发送出去，并继续缓存之后到达的数据。
3. 之后只有在收到对前一个报文段的确认后才继续发送下一个报文段。
4. 另外，Nagel算法还规定：当到达的数据已达到发送窗口大小的一半或已达到MSS时，就立即发送一个报文段。

还有一个问题：糊涂窗口综合症。即在接收方的应用进程读取速度慢的情况下，接收缓存空间有限，传输的数据量小，使得网络效率低。因此这里可以使接收方在缓存已有足够空间容纳一个MSS或者缓存已有一半空间的空闲时再发出确认报文，而发送方也不要发送太小的报文段，而是把数据累积成足够大的报文段或达到接收方缓存空间(接收窗口)的一半大小再进行发送。

#### 5.8 TCP 的拥塞控制
##### 5.8.1 拥塞控制的一般原理
在计算机网络中，链路容量(带宽)、交换节点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫**拥塞**。

拥塞特点：
1. 网络拥塞是一个复杂的问题，有时候仅仅增加资源可能使得网络性能更坏，这很多时候仅仅是将瓶颈转移到其他地方。如某结点缓存的容量小，有时不得不丢弃无法存储的分组。若是将其容量扩展到非常大，则由于数据链路的容量和处理机的速度并未提高，会使得队列中分组的排队时间大大增加，引发超时重传。因此只有所有部分都平衡了，问题才能得到解决。
2. 拥塞常常趋于恶化。因为拥塞中常常会丢弃分组，而这又会引发一次甚至多次重传，这又使得丢弃的分组更多，从而加剧网络的拥塞。

所谓**拥塞控制**就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。进行拥塞控制需要付出代价，首先需要后的网络内部的流量分布信息，在实施控制时，还需要在结点之间交换信息和命令。拥塞控制和流量控制关系密切，但二者存在差别：
1. 拥塞控制是一个全局性的过程，涉及所有的主机、路由器等与降低网络传输性能有关的因素。
2. 流量控制往往指点对点通信量的控制，是个端到端的问题。
3. 二者的相同之处在于，某些拥塞控制算法也是向发送方发送控制报文，告知其放慢发送速率。这与流量控制很相似。

理想拥塞控制：
1. 具有理想拥塞控制的网络，在吞吐量(单位时间内从网络输出的分组数)饱和之前，其值应等于输入负载(单位时间内输入给网络的分组数)。在吞吐量饱和时，其值仍能维持在最大值。
2. 实际情况是吞吐量明显小于理想的吞吐量时，就已经有部分分组被丢弃，网络进入轻度拥塞的状态。而当吞吐量随着输入的负载增大而下降时，网络就进入到了拥塞状态。

拥塞控制方案：
1. 从原理上讲，拥塞控制的方案就是使得 对网络资源的需求 低于 该资源所能提供的可用部分 的方案。这或者是增大网络的某些可用资源，或者减少一些用户对某些资源的需求(这很可能降低服务质量)，但必须要考虑到该措施对其他部分的影响。
2. 拥塞控制是一个动态问题，且网络正朝着高速化的方向发展，这很容易造成分组的丢失。但分组的丢失是网络拥塞的征兆而不是原因。在许多情况下，甚至正是拥塞控制机制本身成为引起网络性能恶化甚至发生死锁的原因。
3. 从大的方面看，可以分为开环控制和闭环控制两种：
   1. 开环控制就是在设计网络时就事先将有关发生拥塞的因素考虑周到，力求网络工作室不发生拥塞，且一旦整个系统运行起来，就不再中途进行改正。
   2. 闭环控制是基于反馈环路的概念，闭环控制的措施是：
      - 监测网络系统以便监测到拥塞在合适、何处发生。一些主要的监测的指标：缺少缓存而丢弃的分组的百分数、平均队列长度、超时重传的分组数等等，这些指标的上升都标志着拥塞的增长。
      - 把拥塞发送的信息传送到可采取行动的地方。通知拥塞发生的分组同样会使网络更加拥塞。
      - 调整网络系统的运行以解决出现的问题。

##### 5.8.2 几种拥塞控制方法
因特网标准中定义了进行拥塞控制的四种算法：慢开始、拥塞避免、快重传和快恢复。
接下来假设接收方总有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度来决定。
###### 5.8.2.1 慢开始和拥塞避免
发送方维持一个拥塞窗口cwnd(congestion window)的状态变量，其值取决于网络的拥塞程度且动态变化。发送窗口 = Math.min(cwnd, rwnd)。发送方控制cwnd 的原则是： 只要没有出现网络拥塞，就将 cwnd 增大一些；而若是出现拥塞，就将拥塞窗口值减小一些。而只要发送方没有按时收到确认报文，就可以认为可能出现了拥塞。

慢开始的思路是：当主机开始发送数据时，由于不清楚网络的负荷情况，较好的办法是先探测一下，即由小增大拥塞窗口。具体为：
1. 通常在开始发送报文段时，将cwnd 设置为一个 MSS 的数值。
2. 每收到一个新的确认报文段，将 cwnd 增加一个 MSS 的数值。
3. 可以看出，每经过一个传输轮次，cwnd 就加倍。一个传输轮次所经历的时间其实就是往返 RTT,不过这里更加强调：把拥塞窗口所允许发送的报文段都连续发送出去，并收到对发送的最后一个字节的确认。
4. 慢开始的“慢”并不是指 cwnd 的增长速率慢，而是比起按照大的 cwnd 一下子将许多报文段突然注入到网络中要慢得多。这对于防止网络拥塞是一个非常有力的措施。

拥塞避免算法的思路是让 cwnd 缓慢地增大，即每经过一个 RTT 就把 cwnd 加一个MSS值(即只要收到一个新的确认，就把 cwnd 增加(MSS / cwnd * MSS)个字节)，而不是加倍。这样使得 cwnd 按线性规律缓慢增大，比慢开始算法的指数增长缓慢得多。

为了防止cwnd 增长过大引起网络拥塞，还需要设置一个慢开始门限状态变量。当cwnd < 慢开始门限值时，使用慢开始算法；反之则使用拥塞避免算法。

无论在慢开始阶段还是拥塞避免阶段，只要发送方判断出现网络拥塞，就将慢开始门限设置为出现拥塞时的发送窗口值的一半(有根据已发送出但还未确认的数据字节数来设置慢开始门限的新公式)，并将cwnd 值重设为 1,执行慢开始算法。这样做可以迅速减少网络中的分组数。

所有慢开始和拥塞避免的流程为：
1. TCP 连接进行初始化时，将 cwnd 置为 MSS值，并设置慢开始门限的初始值(如 16 * MSS)。
2. 执行慢开始算法，当cwnd 增长到值为慢开始门限值时，就使用拥塞避免算法。
3. 当网络出现超时重传后，将慢开始门限值更新为当前拥塞窗口值的一半，拥塞窗口值置为1，并执行慢开始算法重复 1,2,3。
![慢开始和拥塞避免例](/Image/congestion.PNG)

在TCP拥塞控制中常有"乘法减小，加法增大"的说法。乘法减小指不论是在慢开始还是在拥塞避免阶段，只要出现超时，就将慢开始门限减半，当网络频繁出现拥塞时，慢开始门限会下降得很快，可以大大减少注入网络中的分组数。加法增大则是指执行拥塞避免算法时，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。二者合称AIMD算法，使用最为广泛。

###### 5.8.2.2 快重传和快恢复
快重传算法首先要求接收方每收到一个**失序的报文段**后就立即发出重复确认，目的就是使发送方及早直到有报文段没有到达对方。除了第一个之外，之后的都是重复确认。快重传算法规定：发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待该报文段设置的重传计时器到期。

与快重传配置使用的还有快恢复算法：
1. 当发送方连续收到三个重复确认时，执行"乘法减小"算法将慢开始门限减半。这是为了预防网络拥塞，但接下去不执行慢开始算法。
2. 若出现拥塞，则不会一连好几个报文段连续到达接收方，也就不会导致接收方连续发送重复确认，因此此时发送方认为网络很可能没有拥塞。所以接下来是把cwnd 值设置为慢开始门限减半后的数值(也有的实现是设置为慢开始门限减半后的数值 + 3 * MSS)，然后开始执行拥塞避免算法。
3. 采用快恢复算法时，慢开始算法只是在TCP连接建立和网络出现超时时才使用，采用这样的拥塞控制方法使得TCP的性能有明显的改进。

##### 5.8.3 随机早期检测RED
之前讨论的TCP拥塞控制还没有和网络层采取的策略联系起来，实际上，他们之间有着密切的关系。如：若某一个路由器对某些分组的处理时间特别长，则可能引起发送方对这些报文段的重传，这会使得发送方认为网络中出现了拥塞，从而采取拥塞控制的措施，但实际上网络中并没有出现拥塞。

网络层对TCP拥塞控制影响最大的就是路由器的分组丢弃策略。在最简单的情况下，路由器的队列通常都是按照"先进先出"的规则处理到来的分组。因此当队列已满时，以后再到达的所有分组都将被丢弃。这叫做**尾部丢弃策略**。

路由器的尾部丢弃往往会导致一连串分组的丢失，这就使发送方出现超时重传，TCP 进入拥塞控制的慢开始状态。更严重的是，网络中通常有很多的TCP连接，这些连接中的报文段通常是复用在网络层的IP数据报中传送。这时若发生尾部丢弃，则可能同时影响到很多条TCP连接，使许多TCP连接在同一时间进入慢开始状态(这在TCP的术语中称为**全局同步**)。全局同步使得网络中的通信量突然下降了很多，而网络恢复正常后，其通信量又突然增大很多。

为了避免网络中的全局同步现象，可以在路由器采用**随机早起检测RED**，其实现要点如下：
1. 是路由器的队列维持两个参数，即队列长度最小门限TH<sub>min</sub>和最大门限TH<sub>max</sub>。当一份分组到达时，RED 就先计算平均队列长度L<sub>AV</sub>。
2. 若L<sub>AV</sub>小于TH<sub>min</sub>，则将新到达的分组放入队列进行排队。
3. 若L<sub>AV</sub>大于TH<sub>max</sub>，则将新到达的分组丢弃。
4. 若L<sub>AV</sub>在TH<sub>min</sub> 和TH<sub>max</sub> 之间，则按照某一概率p将新到达的分组丢弃。

RED 的 “随机”就体现在步骤 3 中，也就是说，不是等到已经发生网络拥塞后才把所有在队列尾部的分组丢弃，而是在检测到网络拥塞的**早期征兆**时就先以概率 p 随机丢弃个别的分组，从而使得网络拥塞只在个别TCP 连接上进行，避免发生全局性的拥塞控制。

TH<sub>min</sub> 必须足够大，以保证连接路由器的输出链路有较高的利用率。而TH<sub>min</sub>和TH<sub>max</sub>之差也应当足够大，使得在一个TCP往返时间RTT中队列的正常增长仍在TH<sub>max</sub>之内。若门限值设置得不合适，则也可能引发全局振荡。

因为计算机数据具有突发性的特点，因此丢弃概率按照瞬时队列长度来计算可能出现一些不合理现象。如：很短的突发数据不太可能是队列溢出，而若按照瞬时队列长度计算就可能丢弃分组从而产生不必要的拥塞控制。

总之，RED的好处就是当平均队列长度超过门限值TH<sub>min</sub>时，就会有少量的分组被丢弃，从而使得少量的TCP连接减小其窗口值，减少到达路由器的分组数。结果，队列平均长度就减小了，从而避免了网络拥塞的发生，而网络的吞吐量仍然保持在较高的数值。

RED 只是尽可能使尾部丢弃不要发生，而若是某一时刻的瞬时队列长度远远超过平均队列长度，路由器的队列无法接纳新到达的分组，则 RED 的操作和尾部丢弃时相同的。

#### 5.9 tCP的运输连接管理
运输连接有三个阶段：连接建立、数据传送和连接释放。
在TCP的连接过程中要解决三个问题：
1. 要使每一方能够确知对方的存在。
2. 要允许双方协商一些参数(如最大窗口值、是否使用窗口扩大选项和时间戳选项以及服务质量等)。
3. 能够对运输实体资源(如缓存大小、连接表中的项目等)进行分配。
TCP 连接的建立采用客户服务器的方式，主动发起连接建立的应用进程叫做**客户**，而被动等待连接建立的应用进程叫做**服务器**。

##### 5.9.1 TCP的连接建立
接收方的TCP服务器进程先创建**传输控制块TCB**(存储了每一个连接中的一些重要信息，如TCP连接表，到发送和接收缓存的指针，当前的发送和接收序号等), 准备接受客户进程的连接请求。
发送方的TCP客户进程也是首先创建传输控制块TCB,然后向接收端发出连接请求报文段。整体连接过程如下：
1. 发送方的TCP客户进程向接收方发出连接请求报文段，此时首部中的同部位SYN = 1，同时选择一个初始序号 seq = x。TCP 规定，SYN报文段(SYN = 1的报文段)不能携带数据，但要消耗掉一个序号。 这时，TCP客户进程进入SYN-SENT状态。
2. 接收方收到请求报文后，若同意建立连接，则向发送发发送确认。确认报文段中SYN和ACK都置1，确认号ack = x + 1, 同时还要选择一个初始序号seq = y。该报文段同样不能携带数据，要消耗掉一个序号。此时，TCP服务器进程进入SYN-RVCD状态。
3. TCP 客户进程在收到接收方的确认后，还要向接收方发出确认。确认报文段中 ACK置 1， 确认号ack = y + 1，自己的序号seq = x + 1。 TCP规定：ACK报文段可以携带数据，若不携带数据则不消耗序号,这种情况下，TCP连接已经建立，发送方进入ESTABLISHED状态。
4. 接收方收到确认，也进入 ESTABLISHED状态。

![TCP 连接建立](/image/TCP-connection.PNG)

整个连接过程称为**三次握手**，发送方再次发送确认是为了防止已失效的连接请求报文段突然又传送到了接收方(比如第一个连接请求报文段在某些网络节点长时间滞留了)，接收方会认为这是一个新的连接请求，从而发出确认报文段。如果不采用三次握手，则发送方不会理睬该确认报文段，但接收方会认为连接已经建立，并等待发送方的数据，浪费了接收方的资源。

##### 5.9.2 TCP 的连接释放
数据传输结束后，通信的双方都可释放连接。当前发送方和接收方都处于 ESTABLISHED 状态：
1. 发送方的应用进程发出连接释放报文段，并停止在发送数据，主动关闭TCP连接。报文段首部 FIN 置 1, 序号 seq = u(之前传送过的数据的最后一个字节的序号加1)。发送方进入 FIN-WAIT-1 状态，等待 接收方 的确认。FIN 报文段即使不携带数据，也消耗一个序号。
2. 接收方收到连接释放报文段后即发出确认。确认号 ack = u + 1, 序号 seq = v(之前传送过的数据的最后一个字节的序号加1)。接收方进入 CLOSE-WAIT 状态。

此时TCP连接处于半关闭状态，即发送方已经没有数据要发送。但接收方若要发送数据，发送方仍要接收。也就是说，从接收方到发送方的连接并未关闭，这个状态可能持续一段时间。

3. 发送方收到接收方的确认后，进入 FIN-WAIT-2 状态，等待接收方发出的连接释放报文段。
4. 若B 已经没有要向A 发送的数据，其应用进程就通知释放连接，B发出连接释放报文段。报文段首部 FIN = 1, 序号 seq = w(B可能又发送了一些数据)，还需要重复上次发送过的确认号ack = u + 1。B 进入 LAST-ACK 状态，等待A的确认。
5. A收到B的连接释放报文段之后，必须对此发出确认。确认报文段首部 ACK = 1, ack = w + 1, 序号 seq = u + 1。进入TIME-WAIT 状态。此时TCP连接还未释放，必须经过时间等待计时器设置的时间2 * MSL(最长报文段寿命)后，A才进入 CLOSED状态。之后才能开始建立下一个新的连接。

A 在TIME-WAIT等待 2 * MSL 的时间有两个原因：
1. 保证 A 发送的最后一个ACK报文段能够到达B。若是该报文段丢失，则B会重发连接释放报文段，A就能在2 * MSL 时间内收到重传的报文段，接着重传确认并重新启动 2 * MSL 计时器。最后，A 和 B 都正常进入到CLOSED 状态。
2. 防止之前提到的 "已失效的连接请求报文段"出现在本连接中，经过 2 * MSL 时间，本连接持续的时间内所产生的所有报文段都会消失。这可以使下一个新的连接中不会出现旧的连接请求报文段。
3. B 收到A 的确认后，进入CLOSED状态。同样，B在撤销响应的TCB之后(因为B 可能再发送数据，所以A 的TCB撤销在B之后)，就结束了TCP连接。这里B结束TCP连接的时间要比A早一些。

![TCP 连接释放](/image/TCP-disconnection.PNG)

整个连接释放过程称为四次握手。除了时间等待计时器之外，TCP 还设有**保活计时器**。服务器每收到一次客户的数据，就重新设置保活计时器(通常2小时)，若计时器到期都没有收到客户的数据，则服务器就发送一个探测报文段，若没有收到响应，之后则每隔75 分钟发送一次。若一连发送 10 个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。若客户端主机突然出现故障，保活计时器的使用可以节省服务器的资源，使服务器不必白白等下去。

参考：
- TCP 连接建立与释放图片来自[TCP连接和关闭](https://blog.csdn.net/qq_35546040/article/details/80280900)


### 6 应用层
应用层的任务是通过应用进程间的交互来完成特定网络应用，它数据单元是报文(message)

运输层为应用进程提供了端到端的通信服务，但不同的网络应用之间，还需要不同的通信规则。因此在运输层协议之上，还需要有应用层协议。网络上很多功能必须通过位于不同主机中的多个应用进程之间的通信和协同工作来完成，这种通信必须遵循严格的规则，应用层的具体内容就是精确**定义这些通信规则**。具体来说，应用层协议应当定义：
- 应用进程交换的报文类型，如请求报文和响应报文。
- 各种报文类型的语法，如报文中的各个字段及其详细描述。
- 字段的语义，即包含在字段中的信息的含义。
- 进程何时、如何发送报文，以及对报文进行响应的规则。

应用层协议是网络应用的一部分，如：万维网应用包含浏览器、服务器、万维网文档的格式标准，以及一个应用层协议(HTTP)。

#### 6.1 域名系统DNS
##### 6.1.1 域名系统概述
DNS 是因特网使用的命名系统，用来把便于用户使用的机器名转换为IP地址。机器处理IP数据报是使用IP地址而不是域名，是因为IP地址长度固定(IPv4 32位，IPv6 128位)，而域名不定长，机器处理起来比较困难。

因特网采用层次树状结构的命名方法，并使用分布式的域名系统DNS。域名到IP地址的解析是由分布在因特网上的许多**域名服务器程序**共同完成，运行这些程序的机器常被称为**域名服务器**。域名到IP地址的解析过程要点如下：
1. 当某应用进程需要把主机名解析为 IP 地址时，该应用进程就调用 **解析程序**，并成为DNS的一个客户(client)，把待解析的域名放在DNS请求报文中，以UDP用户数据报方式(为了减少开销)发送给本地域名服务器。
2. 本地域名服务器在查找域名后，把对应的IP地址放在回答报文中返回。应用进程获得该IP地址后即可进行通信。
3. 若本地域名服务器不能回答该请求，则该机器就暂时成为DNS中的另一个客户(client)，并向其他域名服务器发出查询请求。直到找到能回答该请求的域名服务器为止。
##### 6.1.2 因特网的域名结构
任何一个连接在因特网上的主机或路由器，都有一个唯一的层次结构的名字，即**域名**。这里，域是可被管理的划分，域还可以被划分为子域，而子域还可继续划分为子域的子域，这样就形成了顶级域、二级域、三级域等等。

域名规则：
1. 每一个域名都是由标号组成，各标号之间用点隔开。标号由英文字母和数字组成，可以使用连字符(-),每一个不超过 63 个字符，不区分大小写。
2. 各级域名由其上一级的域名管理机构管理，用这种方法可使每一个域名在整个因特网范围内是唯一的，并且也容易设计出一种查找域名的机制。
3. 域名中的点(数目不确定)和点分十进制中(一定是三个点)的点无一一对应关系。
4. 一旦某个单位拥有了一个域名，它就可以自己决定是否要进一步划分其下属的子域，且不必其上级机构批准。
##### 6.1.3 域名服务器
从理论上讲，可以让每一级的域名都有一个相对应的域名服务器，但这样会使域名服务器数量太多，降低域名系统的运行效率。因此DNS采用分区的办法来解决这个问题。

一个服务器所管辖的范围叫做区，在一个区中所有节点必须是能够连通的。每一个区中设置相应的**权限域名服务器**,用来保存该区中的所有主机的域名到IP地址的映射。总之，DNS服务器的管辖范围不是以“域”为单位，而是以“区”为单位。区是 DNS 服务器的实际管辖范围，区可能等于或小于域，但一定不可能大于域。

根据域名服务器所起的作用，可以把域名服务器划分为四种不同的类型：
1. 根域名服务器：
   - 所有根域名服务器都知道所有的顶级域名服务器的域名和IP地址。
   - 无论是哪一个本地域名服务器，只要对某个域名无法解析，就首先求助于根域名服务器。在许多情况下，根域名服务器不直接返回对应的IP地址，而是告诉本地域名服务器下一步应该找哪一个顶级域名服务器进行查询。

2. 顶级域名服务器：负责管理在该顶级域名服务器注册的所有二级域名。收到DNS请求时，就给出相应的回答(可能是最后的结果，也可能是下一个域名服务器的IP地址)。
3. 权限域名服务器：负责一个区的域名服务器。收到DNS请求时，给出最后的结果或是下一步应当找哪一个权限域名服务器。
4. 本地域名服务器：
   - 当一个主机发出DNS查询请求时，该请求报文就发送给本地域名服务器。
   - 本地域名服务器离用户较近，一般不超过几个路由器的距离。当所查询的主机也属于同一个本地ISP时，该本地域名服务器就能立即返回IP地址，而不需再询问其他的域名服务器。

为了提供可靠性，DNS域名服务器都把数据复制到几个域名服务器来保存，其中一个是**主域名服务器**，其他的是**辅助域名服务器**。当主域名服务器出故障时，就可以保证DNS的查询工作不会中断。而主域名服务器定期将数据复制到辅助域名服务器中，且更改数据只能在主域名服务器中进行，这就保持了数据的一致性。

域名的解析过程：
1. 主机向本地域名服务器的查询一般都是采用**递归查询**：若本地域名服务器不知道被查询域名的IP地址，就以DNS客户的身份，向其他根域名服务器发出查询请求报文，而不是让主机自己进行下一步查询。因此递归查询的查询结果就是所要查询的IP地址或者报错(表示无法查询到所需的IP地址)。
2. 本地域名服务器向根域名服务器的查询通常采用**迭代查询**：根域名服务器收到查询请求报文后，要么返回对应的IP地址；要么返回下一个域名服务器的地址，然后然本地域名服务器自己查询。若未找到对应IP, 根域名服务器一般返回顶级域名服务器的IP，而若顶级域名服务器也未找到对应IP，则返回权限域名服务器。

本地域名服务器就这样使用迭代查询，直到找到对应所要解析的IP地址，然后返回该IP地址。当然，本地域名服务器也可以采用递归查询，这取决于最初的查询请求报文的设置是要求使用哪一种查询方式。

为了提高DNS查询效率，并减轻域名服务器的负荷和减少因特网上的DNS查询报文数量，在域名服务器中广泛地使用了**高速缓存**。高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录：
- 这样不仅可以大大减轻根域名服务器的负荷，也能够使因特网上的DNS查询请求和回答报文的数量大大减少。
- 许多主机也会从本地域名服务器下载域名和地址的数据，维护存放自己最近使用的域名的高速缓存。
- 域名到地址的绑定可能会改变，因此域名服务器应为每项内容设置计时器并处理超过合理时间的项，一般在查询请求的响应报文中会带有该绑定有效的时间值。

#### 6.4 万维网WWW
##### 6.4.1 万维网概述
万维网是一个大规模的、联机式的信息储藏所，万维网用链接的方法能非常方便的从因特网上的一个站点访问另一个站点。每一个万维网站点都存放了许多文档，而这些文档中又可以有其他链接，通过点击这些链接可以从当前文档链接到可能相隔很远的另一个文档。

万维网的出现，使因特网变为普通百姓也能利用的信息资源，使网站数按指数规律增长。因此，万维网的出现是因特网发展中的一个非常重要的里程碑。

万维网特点：
1. 万维网是一个分布式(非分布式系统中，各种信息都驻留在单个计算机的磁盘中)的**超媒体**系统，他是**超文本**系统的扩充：
   - 超文本是包含指向其他文本的链接的文本，一个超文本由多个信息源链接成，超文本是万维网的基础。
   - 超文本仅包含文本信息，而超媒体文档还包含图形、声音、动画甚至视频等其他信息。
2. 万维网把大量信息分布在整个因特网上，每台主机上的文档都独立进行管理。这样，万维网之间的链接就经常会不一致。
3. 万维网以客户-服务器方式工作，浏览器就是在用户主机上的万维网客户程序。
4. 万维网需要解决的几个问题：
   - 标志整个因特网上的万维网文档：统一资源定位符URL。
   - 实现万维网上各种链接的协议：超文本传送协议HTTP。
   - 不同作者的不同风格的万维网文档，都能在因特网上的各种主机上显示出来：超文本标记语言HTML。
   - 用户能够很方便地找到所需的信息：搜索工具。
##### 6.4.2 统一资源定位符URL
URL 是用来表示从因特网上得到的资源位置和访问这些资源的方法。URL 相当于一个文件名在网络范围的扩展，因此，URL是与因特网相连的机器上的任何可访问对象的一个指针。URL 的一般形式有4个部分组成：`<协议>://<主机>:<端口>/<路径>`。现在最常用的协议是 http,https，其次是 ftp。
##### 6.4.3 超文本传送协议HTTP
HTTP是**面向事务**的应用层协议，它是万维网上能够可靠地交换文件的重要基础。这里的面向事务指一系列的信息交换是一个不可分割的整体，即要么所有的信息交换都完成，要么一次交换都不进行。

万维网的大致工作过程：
1. 每一个服务器进程都在不断地监听TCP的端口80，以便发现是否有浏览器向它发出连接建立请求。
2. 建立TCP连接之后，浏览器就向服务器发出浏览某个页面的请求。
3. 服务器返回所请求的页面作为响应。
4. TCP连接释放。

在浏览器和服务器之间的请求和响应的交互，必须按照规定的格式和遵循一定的规则，这些格式和规则就是超文本传送协议HTTP。

HTTP协议是无状态的，即服务器不知道第一次和第二次访问的客户是否是同一个，这简化了服务器的设计，使服务器更容易支持大量并发的HTTP请求。

传输特点：
1. http/1.0 的主要缺点在于开销，客户端可以在三次握手第三个报文段中捎带HTTP请求，这样请求一个文档的时间有两倍RTT的开销(TCP连接的建立，以及服务器发送回响应)。另一种开销在于客户端和服务器要为每一次新建立的TCP连接分配缓存和变量。而服务器往往要同时服务大量客户的请求，所以这种非持续连接会使万维网服务器的负担很重。

浏览器能够打开 5~10 个并行的TCP连接，每一个TCP连接处理客户的一个请求，因此使用并行的TCP连接可以缩短响应时间。

http/1.0 中持续连接是关闭的，需要在http header 中加入：`connection: keep-alive; keep-alive: timeout = 5, max = 1000`类似的内容才能持续连接。而 http/1.1 中默认启用持续连接，加入 `connection: close` 才关闭。

2. http/1.1 较好地解决了开销的问题，它使用了持续连接。所谓持续连接就是万维网服务器在发送响应后仍然在一段时间内保持这条连接，使同一个客户和该服务器可以继续在这条连接上传送后续的HTTP请求和响应报文。在TCP建立连接的初期有慢开始的特性，所以连接的重用总是比新建连接性能要好。

http/1.1 的持续连接有两种工作方式：
- 非流水线方式：客户在收到前一个响应后才能发出下一个请求。所以在TCP连接建立后，客户每次访问都要用去一个往返时间RTT,相比非持续连接，节省了建立TCP连接所需的一个RTT时间。缺点在于服务器发送完一个响应后，其TCP连接就处于空闲状态，浪费了服务器资源。
- 流水线方式：客户在收到HTTP的响应报文之前就能够接着发送新的请求报文，客户端可以连续发送请求报文，服务器也可以连续发回响应报文。因此，客户访问所有的资源只需花费一个RTT时间。流水线工作方式使TCP连接中的空闲时间减少，提高了下载文档效率。

HTTP/1.1的持久连接和管道机制允许复用TCP连接，但是即使管道机制允许浏览器同时发出多个请求，所有的数据通信都是按次序完成的，服务器只有处理完一个回应，才会处理下一个回应。这样如果前面的回应特别慢，后面就会有很多请求排队等着，这成为 "队头阻塞"。

##### 6.4.4 代理服务器
**代理服务器**是一种网络实体，又称为**万维网高速缓存**。代理服务器把最近的一些请求和响应暂存在本地磁盘中，新请求到达时，若代理服务器发现这个请求与暂时存放的请求相同，就返回暂存的响应，而不需要按照URL的地址再次去因特网访问该资源。

使用了代理服务器之后，访问因特网的过程如下：
1. 浏览器向因特网的服务器请求服务时，先和代理服务器建立TCP连接，并发出HTTP请求报文。
2. 若代理服务器已经存放了请求对象，则将其放入HTTP响应报文中发送回浏览器。
3. 否则，代理服务器就代表发出请求的浏览器，与因特网上的源点服务器建立TCP连接，并发送HTTP请求报文。
4. 源点服务器将所请求的对象放在HTTP响应报文中返回给代理服务器。
5. 代理服务器在收到对象后，先复制一份在自己的本地存储器中，然后在将其放在HTTP响应报文中，返回给浏览器。

可以看出，代理服务器有时是作为服务器，有时又是作为客户。

##### 6.4.5 HTTP的报文结构
http请求报文和响应报文都是由三个部分组成。请求报文：请求行(方法，URL，http版本)、首部行、实体主体；响应报文：状态行(http版本，状态码，解释状态码的简单短语)、首部行、实体主体。


参考：
- https://juejin.im/post/5de372c2f265da060078039a
- https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%B8%83%E5%B1%82%E5%8D%8F%E8%AE%AE


bit Mb  域名区分，突破浏览器的连接限制，提高并行能力 http 如何保证请求和相应的对应　URI 和URL  wireshark抓包  https 双向认证
数据链路层差错检测丢弃，而传输层差错检测要重传
