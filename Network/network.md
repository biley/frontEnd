***
### 1. 分层

OSI 7层和 TCP/IP 5层：
![network layoer](/Image/networkLayer.png)

从一般概念上讲，计算机或网络互连要使用一些中间设备：
- 物理层 —— 转发器
- 数据链路层 —— 网桥或桥接器
- 网络层 —— 路由器
- 网络层以上 —— 网关
转发器和网桥仅仅是把一个网络扩大了，路由器连接网络。

### 2 物理层
1. 为设备之间的数据通信提供传输媒体(电缆、光纤、无线信道)及互连设备。
2. 传输数据(比特流(0, 1)信号)。
### 3 数据链路层
要在一条线路上传递数据，除了必须有一条物理线路外，还必须有一些通信协议来控制这些数据的传输，若把这些实现协议的软件硬件加到物理链路上，就构成了数据链路。

主要功能(为网络层提供数据传送服务)：
1. 封装成帧(frame)：接收端能够从物理层上交的比特流中根据首尾部标记识别出帧，并取出数据
2. 透明传输：无论什么样的比特组合都能够通过，对首尾标识以及转义字符的转义
3. 差错检测：比特在传输过程中可能出错(循环冗余检验)：
    - 在通信质量良好的有线链路，数据链路层丢弃错误帧，即只保证接收的帧无差错，确认和重传由上层协议来完成。(帧比较小，正确率高的情况下每一帧都要确认比较耗费资源)
    - 在通信质量差的无线链路，数据链路层使用确认和重传机制，向上提供可靠传输的服务。(正确率低时，上层数据报频繁重发会使得很多成功发送的帧重发)

数据链路层最常见的独立产品是网卡(计算机MAC地址)，网桥(根据MAC帧的目的地址对收到的帧进行转发和过滤)。

数据链路层的信道主要分为：
1. 点对点信道，PPP协议
2. 广播信道，CSMA/CD协议(以太网)

### 4 网络层
发送数据时，网络层负责把运输层产生的报文段或用户数据报封装成`IP数据报(datagram)`进行传送；另一个任务是选择合适的路由，使得IP数据报能够通过网络中的路由器找到目的主机(也就是路由或寻径)。

网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务，所传送的分组可能出错、丢失、重复和失序。

##### 4.1 网际协议IP
网际协议IP是作用是使互连起来的许多计算机网络之间能够进行通信，与之配套使用的还有ARP,ICMP,IGMP。

IP协议可以使各个性能各异的网络在网络层看起来像是一个同一个网络。

IP地址特点：
- IP地址一般有两个部分组成：网络号和主机号。A类、B类和C类地址的区分已成为历史。
- IP地址是32位的二进制代码，为提高可读性，使用点分十进制记法。
- 网络号全0 表示“本网络”，主机号全0表示“本主机”；网络号为 127 保留作为本地软件环回测试本主机的进程之间的通信只用，主机号全 1 表示该网络上的所有主机。B类C类不会出现网络号全为0或1的情况。
- 一个网络指具有相同网络号的主机的集合，因此用转发器或网桥连接起来的若干个局域网仍为一个网络。路由器每一个接口都有一个不同网络号的IP地址(路由器直连时可能不会分配IP地址)。

IP地址与硬件地址(物理地址、MAC地址)：
- 硬件地址是数据链路层和物理层使用的地址，IP地址是网络层及以上使用的地址，是一种逻辑地址。
- 使用IP地址(首部中)的IP数据报在数据链路层被封装成MAC帧，MAC帧在传送时使用的源地址和目的地址都是硬件地址(MAC帧首部中)。
- 在路由器中转发时，IP数据报首部中的源地址和目的地址始终都不会变化，而MAC帧首部中的源地址和目的地址都要发生变化。

网络层抽象的互联网屏蔽了下层复杂的细节，使我们得在网络层上讨论问题时，能够使用统一的、抽象的IP地址研究主机和主机或路由器之间的通信。

###### 4.1.2 ARP
ARP解决的是(同一个局域网上)已知一个机器(主机或路由器)的IP地址，需要找出其相应的硬件地址的问题。

网络层使用的是IP地址，但实际在网络的链路上传送数据帧时，还是必须使用网络的硬件地址。但IP地址和MAC地址由于格式不同而没有简单的映射关系，且主机的加入、撤走，更换网卡都可能导致MAC地址改变。ARP的解决办法就是在主机(路由器)ARP高速缓存中存放本局域网上各主机从IP地址到MAC地址的映射表，且该表经常动态更新(新增或超时删除)。

ARP特点：
- 当一个主机向另一个主机发送数据时，若在映射表中找不到目的主机的IP地址项目，则源主机自动运行ARP,ARP进程在局域网广播发送一个APR请求分组，对应的主机会以单播的形式响应分组。
- ARP把映射表中的每一个项目都设置生存时间，超过生存时间的就删除。
- 从IP地址到硬件地址的解析是自动进行的，主机用户对这种地址解析过程并不知情。只要主机要和本网络上的一个已知IP地址的主机或路由器进行通信，ARP协议就会自动将IP地址解析为MAC地址。

###### 4.1.3 IP数据报格式
IP数据报由首部和数据两部分组成。首部分固定首部和可选字段。固定首部中包含了版本、首部长度、总长度、标识、标志、片偏移、生存时间、协议、首部校验和等字段。

IP数据报分片(一个IP数据报分成多个IP数据报)：
- 总长度字段为 16 位，因此数据报最大长度为 2^16 - 1 字节。而每一种数据链路层协议都规定了一个数据帧中数据字段的最大长度，这称为MTU。若传送的IP数据报长度超过MTU,就必须把过长的数据报进行分片处理。
- 虽然IP数据报越长，传输效率越高(分片少，首部长度占总长度比例小)；但IP数据报越短，路由器转发速度越快。因此IP协议规定路由器和主机必须能接受长度不超过576字节的数据报；若超过，则需要先了解目的主机能否接受该长度，不能就要分片。
- 标识在数据报分片时，会被复制到所有数据报片的标识字段，使得各分片最后能正确重装为原来的数据报。
- 标志占3位，目前两位有意义。最低位记为MF,MF为1表示后面还有分片；MF为0表示已经是分片中的最后一个。中间一位记为DF,DF为1表示不能分片；DF为0表示允许分片。
- 片偏移表示某片在原分组中的相对位置，既相对数据字段的起点。片偏移以8字节为偏移单位，所以每个分片一定是8字节(64位)的整数倍。
- 生存时间TTL，占8位 目的是防止无法交付的数据报无限制的在因特网中兜圈子。TTL 从时间限制(技术进步，路由器处理数据报所需时间不短缩短)改为跳数限制，路由器转发之前将TTL(最大255)减1,若为0 就丢弃。

首部的可选字段增加了路由器处理数据报的开销，而很少被使用，因此IPv6把IP数据报的首部长度做成固定的。

###### 4.1.4 IP层转发分组流程
按照主机号来制作路由表会导致路由表过于庞大，所以按照网络地址来制作。路由表每一行最主要的是目的主机所在网络和下一跳地址，若不需再经过路由器，则可通过接口直接交付(路由器中有ARP映射表)。

其他路由：
- 因特网中所有的分组转发都是基于目的主机坐在网络，但允许有这样的特例：对特定的目的主机指明一个路由，叫做特定主机路由。可使网络管理人员能更方便的控制网络和测试网络，或用在考虑某种安全问题的情况下。
- 路由器可以采用默认路由来减少路由表所占用的空间和搜索路由表所用的时间。这种方式在一个网络只有很少的对外连接时很有用。

分组转发算法：
1. 从数据报首部提取目的主机的IP地址D，得出网络地址N。
2. 若N与路由器直接相连，则直接交付；否则3。
3. 若路由表中有D的特定主机路由，则把数据报传送给路由表中指明的下一跳路由；否则4。
4. 若路由表中有到达N的路由，则把数据报传送给路由表中指明的下一跳路由；否则5。
5. 若路由表中有默认路由，则把数据报传送给路由表中指明默认路由器；否则6。
6. 报告转发分组出错。

##### 4.2 划分子网
两级IP地址缺点：
1. 网络地址利用率低。
2. 给每一个物理网络分配一个网络号会使得路由表变得太大(存储空间、查找时间、定期交换的路由信息急剧增加)，而使网络性能变坏。
3. 两级地址不够灵活，开通一个新的网络必须申请到一个新的IP地址。

为了解决两级IP的缺点，在IP地址中又增加了一个“子网段号”，将两级IP地址变成三级IP地址，这就是划分子网。

划分子网思路是：从网络的主机号借用若干位作为子网号，因此即使分配了多个子网，对外依然表现为一个网络。而与网络连接的路由器在收到IP数据报后，再按目的网络号和子网号找到目的子网，把IP数据报交付目的主机。
###### 4.2.1 子网掩码
从IP数据报的首部无法看出源主机或目的主机所连接的网络是否进行了子网划分，因此需要**子网掩码**：
子网掩码也是32位，由一串1(对应网络号和子网号)跟随一串0(对应主机号)组成。

使用子网掩码的好处是：无论网络有无子网，只要把IP地址和子网掩码逐位“与”，就可以立即得到网络地址，路由器可以对到来的分组统一处理。为了便于查找路由表，规定所有的网络都必须使用子网掩码，路由表中也必须有子网掩码这一栏；路由器在和相邻路由器交换信息时(链路层广播?)，也必须把自己所在网络的子网掩码带上。若网络不划分子网，则其子网掩码就是**默认子网掩码**(一串1正好和网络号对应)

使用子网划分后，路由表必须包含：目的网络地址、子网掩码、下一跳地址三项。这时的分组转发算法与**1.3.4**中分组转发类似,只是不再需要网络地址N,并将交付或转发的条件变成检查 “子网掩码和IP地址逐位‘与’的结果与目的网络地址是否匹配”。

##### 4.3 无分类编制CIDR(构成超网)
划分子网在缓解了因特网在发展中遇到的困难，但依然有三个必须尽早解决的问题：
1. 网络地址不够，B类地址即将分配完毕。
2. 因特网主干上的路由表项目数量急剧增长。
3. 整个IPv4 地址空间终即将全部耗尽。
其中问题1、2迫在眉睫，IETF 研究出采用**无分类编制**
的方法来解决他们。该方法的正式名字为**无分类域间路由选择CIDR**,它最主要的特点有两个：
1. 消除了A类、B类和C类地址及划分子网(CIDR 不使用子网是指没有在32位中指明若干位作为子网字段，但分配到一个CIDR地址块的单位依然可以在内部根据需要划分出一些子网)的概念。CIDR把32为的IP分为两个部分。IP地址 ::= {<网络前缀>，<主机号>}。CIDR还使用斜线记法，即在IP地址后面加上斜线"/",然后写上网络前缀所占的位数。
2. CIDR把网络前缀都相同的连续的IP地址组成一个CIDR地址块。CIDR使用32位的**地址掩码**，其中1的个数就是网络前缀的长度，CIDR使用的地址掩码也可以继续称为子网掩码。

一个CIDR地址块中有很多地址，在路由表中利用CIDR地址块来查找目的网络，这种地址的聚合常称为**路由聚合**，它使得路由表中的一个项目可以表示原来传统分类地址的很多个路由。路由聚合也称为**构成超网**。CIDR的另一个好处是可以更加有效的分配IPv4的地址空间，而分类地址则只能分配A类、B类和C类。

使用构成超网后的路由匹配特点:
1. 最长匹配前缀
   
   路由表中项目主要由网络前缀、地址掩码和吓一跳地址组成。在查找路由表是可能会得到不止一个匹配结果，这时就应当从匹配结果中选择具有最长网络前缀的路由。
2. 使用二叉线索查找路由表
   
   由于要寻找最长匹配前缀，路由表的查找过程变得更加复杂。为了更加有效的查找，通常是把路由表存放在一种层次的数据结构中，然后自上而下的按层次进行查找。这里最常用的就是**二叉线索**，其每一个叶节点代表一个唯一前缀。二叉线索只是提供了一种可以快速在路由表中找到匹配的叶节点的机制，还需要和子网掩码进行逻辑与运算来确定是否和网络前缀比配。

##### 4.4 网际控制报文协议ICMP
为了更有效地转发IP数据报和提高交付成功的机会，在网际层使用了ICMP,它允许主机或路由器报告差错情况和提供有关异常情况的报告。虽然ICMP报文装在IP数据报中，作为其中的数据部分，但ICMP不是高层协议。

ICMP报文的种类有两种：
1. ICMP 差错报告报文
   - 终点不可达
   - 原点抑制
   - 时间超过
   - 参数问题
   - 改变路由(重定向)：主机不和连接在网络上的路由器定期交换路由信息，而是发送数据报到默认路由器；若重定向，则主机修改路由表。
2. ICMP询问报文
   - 回送请求或回答。 一个重要应用是分组网间探测PING,用来测试两个主机之间的连通性。PING是应用层直接使用网络层ICMP的一个例子，没有通过运输层的TCP或UDP。另一个非常有用的应用是traceroute,用来跟踪一个分组从源点到终点的路径。
   - 时间戳请求或回答。可用来进行时钟同步伐和测量时间。

##### 4.5 因特网路由选择协议
##### 4.6 IP多播

### 5 运输层
运输层负责向两个主机的进程之间的通信提供**通用**的数据传输服务。网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信；此外，运输层还要对收到的报文进行差错检测。

通用：多个应用可以使用同一个运输层服务，而一台主机可以同时运行多个进程，因此运输层有**复用**和**分用**的功能。复用指多个应用进程，分用则指运输层在剥去报文的首部后能够把这些数据正确交付目的相应进程。

主要使用协议：
- 传输控制协议TCP(Transmission Control Protocol): 提供面向连接的、可靠的数据传输服务，数据传输单位指TCP报文段(segment);其逻辑通信信道相当于一条全双工的可靠信道。
- 用户数据报协议UDP(User Datagram Protocol): 提供无连接的，尽最大努力的数据传输服务，数据传输的单位是UDP用户数据报;其逻辑通信信道仍然是一条不可靠信道。

##### 5.1 运输层的端口
要实现运输层的复用和分用，则给应用层每个应用进程赋予一个非常明确的标志是至关重要的。虽然单个计算机中的进程有进程标识符(进程ID)来标志，但不同操作系统使用的进程标识符不同。而为了运行在不同操作系统上的进程能够互相通信，必须使用统一的方法对TCP/IP体系的应用进程进行标志。

但是，进程的创建和撤销都是动态的，通信的一方几乎无法识别对方机器上的进程，因此把特定机器上的特定进程指明为因特网上通信的最后终点还是不可行的。解决这个问题的办法就是在运输层使用**协议端口号**,即我们只要把要传送的报文交到目的主机的某一个合适的端口，剩下的工作(最后交付到目的进程)就由TCP 来完成。

端口特点：
1. 这种在协议层间的抽象的协议端口是软件端口，与硬件端口(不同硬件设备进行交互的接口)是完全不同的概念，它是应用层的各种协议进程与运输实体进行层间交互的一种地址。
2. 因特网上的计算机通信是采用客户-服务器方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号，而客户端进程也会在报文中带上自己的端口号。
3. 运输层的端口号分为两大类：
   1. 服务器端使用的端口号，还可以分为两类：
      - 熟知端口号(well-known port number), 数值为 0 ~ 1023。这些数值可以在网上查到，这些端口号被指派给了TCP/IP对重要的一些应用程序，所有用户都可以知道。当一个新的应用程序出现后，必须为其指派一个熟知端口，否则因特网上其他应用进程无法和它进行通信。
      - 登记端口号。数值为 1024 ~ 49151。这类端口号是为没有熟知端口号的应用程序使用的，使用这类端口号必须在IANA登记，以防止重复。
   2. 客户端使用的端口号。数值为 49152 ~ 65535，这类端口号仅在客户端进程运行时才动态选择，因此又叫短暂端口号。

##### 5.2 用户数据报协议UDP
UDP 只在IP的数据报服务之上增加了很少一点功能：复用、分用以及差错检测。UDP的主要特点为：
1. 无连接：减少了开销和发送数据之前的时延。
2. 尽最大努力交付。
3. 面向报文：对应用层交下来的报文，既不合并，也不拆分；而是保留边界，在添加首部后就交付IP层，因此应用程序必须选择合适大小的报文，否则由IP层分片，降低IP层效率；反之，报文短则导致IP数据报首部相对长度太大，降低IP层效率。
4. 无拥塞控制：对某些实时应用很重要，也可能引起网络产生严重的拥塞问题。
5. 支持一对一、一对多、多对一和多对多的交互通信。
6. 首部开销小，8个字节(TCP 20字节)。

UPD首部由四个字段组成：
1. 源端口。
2. 目的端口。
3. 长度(首部加数据)。
4. 检验和(12字节的伪首部)。

##### 5.3 传输控制协议TCP
TCP 协议比较复杂，它最主要的特点是：
1. 面向连接：使用之前，必须建立连接；传送结束后，必须释放连接。
2. 只能点对点(一对一)。
3. 可靠交付：无差错、不丢失、不重复、按序到达。
4. 全双工通信：应用进程在任何时候都能发送数据(TCP连接的两端都设有发送缓存和接收缓存)。
5. 面向字节流：
   - 虽然TCP 与应用程序的交互是一次一个数据块，但TCP仅将其看成是一连串的无结构字节流，TCP不保证应用程序发送的和对方收到的数据块具有对应大小关系，但其字节流是完全相同的。
   - TCP不关心应用进程一次发送多长的报文到缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少字节(划分或积累)。
6. TCP 连接的两个端点不是应用进程，也不是协议端口，而是套接字：套接字 socket = (IP地址：端口号)。这里的 socket 与应用编程接口API(socket API)不同。
##### 5.4 可靠传输的工作原理
理想的传输条件有两个特点：
1. 传输信道不产生差错。
2. 无论发送发发送数据多快，接收方总是来得及处理。
实际网络不直接具备这样的条件，但可以使用一些可靠传输协议，使得：
1. 出错重传。
2. 接收方来不及处理收到的数据时，及时告诉发送方适当降低发送速度。
###### 5.4.1 停止等待协议
主要讨论可靠传输原理，因此把传送的数据单元称为分组。

停止等待就是每发送完一个分组就停止发送，等待对方确认；收到确认后，再发送下一个分组：
1. 发送方每发送完一个分组，就设置一个超时计时器。
2. 发送方只要超过设置的时间没有收到确认，就认为分组丢失，重传分组，这就是**超时重传**；若收到确认，则撤销超时计时器：
   - 发送反发送完分组，必须保留副本(超时重传用)，收到确认后再清除。
   - 分组和确认分组都必须进行编号。
   - 超时计时器的重传时间应该比分组传输的平均往返时间更长一些。
3. 在确认丢失和确认迟到的情况下，发送方都会重发分组，而接受方应该丢弃分组并重新发送确认。
像这样的可靠传输协议通常称为 **自动重传请求ARQ**

信道利用率：发送分组TD, 发送确认时间 TA, 分组往返时间RTT，则利用率 U = TD/(TD + RTT + TA),而发送分组时间TD中再扣除分组等控制信息则利用率更小。因此可以看出，停止等待协议的优点是简单，缺点是信道利用率太低。为了提高传输效率，可以采用流水线传输，即发送发可以连续发送多个分组，而不是每发送一个就停下来等待确认。

使用流水线传输是，就要使用连续ARQ协议和滑动窗口协议。

###### 5.4.2 连续ARQ协议
连续ARQ协议通常结合滑动窗口协议使用，发送方会维持一个发送窗口：
1. 位于发送窗口内的分组可以按照序号从小到大连续发送出去，而不需等待确认，提高信道利用率。
2. 接收方一般采用**累积确认**的方式:不必对分组逐个发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认：
   - 优点：容易时间，即使确认丢失也不必重传(丢失确认的分组 之后的 分组确认 收到了？)。
   - 缺点：不能向发送方反映出接收方已经正确收到的所有分组信息(回退N，通信线路质量不好时，带来负面影响)。

##### 5.5 TCP 报文段首部格式
一个TCP报文段分为首部和数据两部分，其首部的前 20 个字节是固定的，后面有 4n 字节根据需要增加。
首部固定部分字段：
1. 源端口和目的端口： 各占2字节。
3. 序号：
   - 4字节。范围：[0, 2^32 - 1]，达到最大值后有回到0，即 序号使用 mod 2^32 运算。
   - TCP 是面向字节流的，在其中传送的字节流中的每一个字节都按顺序编号。首部中的序号字段值指本报文段所发送的数据的当一个字节的序号。
4. 确认号：4字节。是期望收到对方下一个报文段的第一个字节的序号，因此确认号为 N 表示到序号 N - 1 为止的所有数据都已经正确收到。
5. 数据偏移：占4位。 指出TCP报文段数据起始处距离TCP报文段的起始处有多远，实际就是首部长度。该字段的单位是 32位字(4字节)，4位二进制能表示最大十进制位 15,因此首部最大长度为 60字节。
6. 保留：占6位，保留为今后使用。
7. 紧急URG: 当 URG=1 时，表明紧急指针字段有效。它告诉系统报文中有紧急数据，应尽快传送(相当于高优先级的数据)，而不是按原来的排队顺序传送。这种情况下，发送方TCP一般会把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。
8. 确认ACK: 仅当 ACK=1 时确认号字段才有效。TCP规定，连接建立后所有传送的报文段都必须把ACK置1。
9. 推送PSH: 有时一端的应用进程希望在键入一个命令后立即能够收到对方的响应，这时就可以使用 PSH。发送发TCP把PSH置1，并立即创建一个报文段发送出去，接收方TCP收到PSH=1的报文段，就尽快地交付应用进程(不再等待缓存填满)。接收方是否使用将PSH置1来响应，则属于业务逻辑。
10. 复位RST: 当RST=1 时，表明TCP连接中出现严重差错(主机崩溃或其他原因)，必须释放连接，然后在重新建立运输连接。该字段置1也用来拒绝一个非法的报文段或拒绝打开一个连接。
11. 同步SYN: 在建立连接时用来同步序号。SYN 置 1 表示这是一个连接请求或连接接收报文。
12. 终止FIN: 用来释放一个连接。FIN=1 表示此报文段的发送方的数据已经发送完毕，要求释放运输连接。
13. 窗口： 2字节。值发送此报文段的一方的接收窗口。窗口值告诉对方：从此报文段首部中的确认号算起，接收方目前允许对方发送的数据量。有这个限制是因为接收方的数据缓存空间有限，总之,**窗口值作为接收方让发送方设置其发送窗口的依据， 且窗口值经常动态变化**。
14. 检验和：2字节。检验范围包括首部和数据，计算时，和UDP同样要添加伪首部，区别在于：需要把第4和5个字段分别改为TCP的协议号和TCP长度。
15. 紧急指针：2字节。仅在URG=1 时才有意义，指出了此报文段中紧急数据局的字节数(紧急数据结束后就是普通数据)。即使窗口为0时也可发送紧急数据。
16. 选项：长度可变，最长 40 字节。
    - 最大报文段长度MSS：每一个TCP 报文段中的数据字段的最大长度。太小则网络利用率低，太大则IP层需要分片重组，出错时还要重传，也会使开销增大。所以在IP层不分片的条件下，MSS应该尽可能大。但路径不同，情况不同，最佳MSS 很难确定，所以由传送方将自己能够支持的MSS写入这一字段，默认为 536字节。
    - 窗口扩大：3字节。 对于包含卫星信道的网络，传播时延和贷款都很大，要获得高吞吐率需要跟大的窗口大小。窗口扩大选项中一个字节表示**移位值S**, 新窗口值就等于 16 + S, S允许使用的最大值是 14。
    - 时间戳选项：10 字节。其中最主要的字段是**时间戳值**字段(4字节)和**时间戳回送回答字段**(4字节)。该选项有两个功能：计算往返时间RTT和处理TCP序号超过 2^32 的情况。

##### 5.6 TCP 可靠传输的实现
###### 5.6.1 以字节为单位的滑动窗口
TCP 的滑动窗口以字节为单位

发送窗口特点：
1. 发送方根据确认报文段的窗口和确认号构造出自己的发送窗口。虽然发送窗口有接收窗口设置，但在同一时刻，发送窗口并不总和和接收窗口一样大，因为网络传送窗口值需要经历一定的时间滞后。
2. 发送方在没有收到接收方的确认的情况下，可以连续把窗口内的数据都发送出去。显然，窗口越大，就可能获得更高的传输效率，但接收方必须来得及处理这些收到的数据。
3. 已经发送过的数据，收到确认之前都必须暂时保留，留待超时重传。
4. 发送窗口的位置由窗口前沿("前"移指移向未发送的数据的方向)和后沿的位置共同确定。
   
   后延变化情况两种：不动(未收到新的确认) 和 前移(收到新的确认)。
   
   前沿通常不断向前移动，在两种情况下不动：未收到新的确认 和 收到新的确认但对方通知窗口变小，使得发送窗口正好不动。前沿也可能向后收缩，但TCP的标准强烈不赞成这样做，因为窗口中的数据可能已经发送了很多，若有收缩窗口不让发送，则可能会产生一些错误。
5. 描述一个发送窗口的状态需要 3 个指针 p1(已发送但未收到确认)，p2(允许发送但尚未发送)，p3(不允许发送)。(因为拥塞控制，所以可能不是一次发完，所以存在p2?)
6. 发送方在收到确认后，就把p1移到对应的确认号，p2不动，p3由确认报文中的确认号和窗口值确定。
7. 发送方在发送完发送窗口中的数据后，p2向前移动和p3重合。而又没有再收到确认号，由于发送窗口已满、可用窗口为0，因此必须停止发送。为了保证可靠传输，发送方在经过一段时间后(超时计时器控制)就重传这部分数据，并重置超时计时器，直到收到确认。

缓存和窗口是有关系的，缓存空间和序号空间都是有限的，且都是循环使用的。

发送缓存和发送窗口：
1. 发送缓存用来暂时存放：
   - 发送应用程序传送给发送方TCP准备发送的数据。
   - TCP已经发送但未收到确认的数据。
2. 发送窗口通常只是发送缓存的一部分，已被确认的数据应当从缓存中删除，因此发送缓存和发送窗口的后延是重合的。且发送应用程序必须控制写入缓存的速率，不能太快，否则发送缓存就会没有存放数据的空间。

接收缓存和接收窗口：
1. 接收缓存用来暂时存放：
   - 按序到达，但尚未被接收应用程序读取的数据。
   - 未按序到达的数据。
2. 对于不按序到达的数据处理，TCP 标志并无明确规定。若丢弃，则接收窗口的管理简单，但对网络资源的利用不利。因此TCP通常对不按序到达的数据先临时存放在接收窗口，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。
3. TCP 要求接收方必须有累积确认的功能，以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据发送时把确认信息顺便带上。有两点需要注意：
   - 接收方不应过分推迟发送确认，否则会导致发送方不必要的重传。若收到一连串具有最大长度的报文段，则必须每隔一个报文段就要发送一个确认。
   - 捎带确认不常发生，因为大多应用程序不会同事在两个方向上传送数据。

##### 5.6.2 超时重传时间的选择
TCP下层的互联网环境复杂，每个IP数据报选择的路由还可能不同。若把超时重传时间设置的太短，则会引起很多不必要的重传，是网络负荷增大；若设置得太长，则又使网络的空间时间增大，降低运输效率。
TCP 采用了一种自适应算法：
1. 报文段的往返时间 RTT：报文段发出的时间与收到相应确认的时间之差。
2. 加权平均往返时间 RTT<sub>S</sub>：s为smoothed。第一次测量到 RTT 时，RTT<sub>S</sub> 值就取为该 RTT 值，之后则为：新的Rtt<sub>S</sub> = (1 - α) * 旧的Rtt<sub>S</sub> + α * 新的RTT，推荐 α 为 1/8(0.125)。
3. 超时计时器设置的**超时重传时间 RTO**应该略大于 RTT<sub>S</sub>: RTO = RTT<sub>S</sub> + 4 * TRR<sub>D</sub>。
4. RTT<sub>D</sub>是RTT的偏差的加权平均值：第一次测量时，RTT<sub>D</sub>值为测量到的RTT值的一半，之后则为：新的RTT<sub>D</sub> = (1 - β) * 旧的RTT<sub>D</sub> + β * |RTT<sub>S</sub> - 新的RTT|，推荐 β 的值为 1/4(0.25)。
5. 但对于往返时间的测量，还十分复杂。因为若主机重传了数据报，则由于重传的数据报与原来的报文段完全一样，因此主机收到确认后无法做出正确的判断。Karn 提出了一个算法：只要报文段重传了，就不采用其往返时间样本。但这样做的问题在于：若报文段的时延突然增大了很多，在之前的重传时间内，无法收到确认报文段，因此需要重传。但若不考虑重传时的往返时间样本，则RTO就无法更新。因此对Karn算法的修正是：报文段每重传一次，就把RTO增大一些，典型的做法是设为之前的2倍。当不再发生重传时，则继续使用之前的算法。

##### 5.6.3 选择确认SACK
若收到的报文段无差错，而只是未按序到达，中间还缺少一些序号的数据。那么是否能只传送缺少的数据而不重传已经到达的数据呢，选择确认是一种可行的处理方法。

若要使用SACK,则建立连接时，就要在TCP的首部选项加上允许SACK的选项。在之后的TCP报文段的首部中都增加了SACK选项，以报告收到的不连续的字节块的边界。而首部选项的长度最大为 40 字节，一个边界4字节(序号32位)，另外还需要一个字节指明SACK选项，一个字节指明该选项要占用多少字节，因此选项中最多只能指明4个字节块的边界信息。SACK文档未指明发送方应当怎样响应SACK,因此大多数的实现还是重传所有未被确认的数据块。

#### 5.7 TCP 的流量控制
##### 5.7.1 利用滑动窗口实现流量控制
所谓流量控制就是让发送方发送速率不要太快，要让接收方来得及接收。利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。

接收方通过确认报文段中的ACK,ack以及rwnd(receiver window) 便可以控制发送方的发送窗口大小从而实现流量控制。

需要注意的是若 rwnd 为0,则发送方会暂停发送直到接收方重新发出一个不为0的 rwnd为止。但有可能更新 rwnd 的报文段在传送时丢失，则发送方等待接收方更新发送窗口，而接收方等待发送方发送数据，没有其他措施的情况下，这种死锁局面将一直持续下去。因此TCP为每一个连接设有一个持续计时器，只要发送方接收到 rwnd 为0的确认报文段，就启动该计时器，时间到期就发送一个探测报文段，接收方在确认该报文段时会给出当前窗口值。

##### 5.7.2 考虑传输效率
应用进程将数据传送到TCP缓存后，发送任务由TCP来控制，可以用不同的机制来控制TCP报文段的发送时机，如：
1. TCP维持一个变量，其值为MSS, 只要缓存中的数据到达最大报文段长度MSS,就组装成一个TCP报文段发送出去。
2. 有应用进程指明要求发送报文段(PSH)。
3. 发送方的计时器到期，将已有的缓存数据装入报文段(长度小于MSS)发送出去。

在TCP的视线中广泛使用Nagle算法：
1. 若应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，缓存后面到达的数据字节。
2. 当发送方收到对第一个数据字节的确认后，再把缓存中的数据组装成一个报文段发送出去，并继续缓存之后到达的数据。
3. 之后只有在收到对前一个报文段的确认后才继续发送下一个报文段。
4. 另外，Nagel算法还规定：当到达的数据已达到发送窗口大小的一半或已达到MSS时，就立即发送一个报文段。

还有一个问题：糊涂窗口综合症。即在接收方的应用进程读取速度慢的情况下，接收缓存空间有限，传输的数据量小，使得网络效率低。因此这里可以使接收方在缓存已有足够空间容纳一个MSS或者缓存已有一半空间的空闲时再发出确认报文，而发送方也不要发送太小的报文段，而是把数据累积成足够大的报文段或达到接收方缓存空间(接收窗口)的一半大小再进行发送。

#### 5.8 TCP 的拥塞控制
##### 5.8.1 拥塞控制的一半原理
在计算机网络中，链路容量(带宽)、交换节点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫**拥塞**。

拥塞特点：
1. 网络拥塞是一个复杂的问题，有时候仅仅增加资源可能使得网络性能更坏，这很多时候仅仅是将瓶颈转移到其他地方。如某结点缓存的容量小，有时不得不丢弃无法存储的分组。若是将其容量扩展到非常大，则由于数据链路的容量和处理机的速度并未提高，会使得队列中分组的排队时间大大增加，引发超时重传。因此只有所有部分都平衡了，问题才能得到解决。
2. 拥塞常常趋于恶化。因为拥塞中常常会丢弃分组，而这又会引发一次甚至多次重传，这又使得丢弃的分组更多，从而加剧网络的拥塞。

所谓**拥塞控制**就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。进行拥塞控制需要付出代价，首先需要后的网络内部的流量分布信息，在实施控制时，还需要在结点之间交换信息和命令。拥塞控制和流量控制关系密切，但二者存在差别：
1. 拥塞控制是一个全局性的过程，涉及所有的主机、路由器等与降低网络传输性能有关的因素。
2. 流量控制往往指点对点通信量的控制，是个端到端的问题。
3. 二者的相同之处在于，某些拥塞控制算法也是向发送方发送控制报文，告知其放慢发送速率。这与流量控制很相似。

理想拥塞控制：
1. 具有理想拥塞控制的网络，在吞吐量(单位时间内从网络输出的分组数)饱和之前，其值应等于输入负载(单位时间内输入给网络的分组数)。在吞吐量饱和时，其值仍能维持在最大值。
2. 实际情况是吞吐量明显小于理想的吞吐量时，就已经有部分分组被丢弃，网络进入轻度拥塞的状态。而当吞吐量随着输入的负载增大而下降时，网络就进入到了拥塞状态。

拥塞控制方案：
1. 从原理上讲，拥塞控制的方案就是使得 对网络资源的需求 低于 该资源所能提供的可用部分 的方案。这或者是增大网络的某些可用资源，或者减少一些用户对某些资源的需求(这很可能降低服务质量)，但必须要考虑到该措施对其他部分的影响。
2. 拥塞控制是一个动态问题，且网络正朝着高速化的方向发展，这很容易造成分组的丢失。但分组的丢失是网络拥塞的征兆而不是原因。在许多情况下，甚至正是拥塞控制机制本身成为引起网络性能恶化甚至发生死锁的原因。
3. 从大的方面看，可以分为开环控制和闭环控制两种：
   1. 开环控制就是在设计网络时就事先将有关发生拥塞的因素考虑周到，力求网络工作室不发生拥塞，且一旦整个系统运行起来，就不再中途进行改正。
   2. 闭环控制是基于反馈环路的概念，闭环控制的措施是：
      - 监测网络系统以便监测到拥塞在合适、何处发生。一些主要的监测的指标：缺少缓存而丢弃的分组的百分数、平均队列长度、超时重传的分组数等等，这些指标的上升都标志着拥塞的增长。
      - 把拥塞发送的信息传送到可采取行动的地方。通知拥塞发生的分组同样会使网络更加拥塞。
      - 调整网络系统的运行以解决出现的问题。

##### 5.8.2 几种拥塞控制方法
因特网标准中定义了进行拥塞控制的四种算法：慢开始、拥塞避免、快重传和快恢复。
接下来假设接收方总有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度来决定。
###### 5.8.2.1 慢开始和拥塞避免
发送方维持一个拥塞窗口cwnd(congestion window)的状态变量，其值取决于网络的拥塞程度且动态变化。发送窗口 = Math.min(cwnd, rwnd)。发送方控制cwnd 的原则是： 只要没有出现网络拥塞，就将 cwnd 增大一些；而若是出现拥塞，就将拥塞窗口值减小一些。而只要发送方没有按时收到确认报文，就可以认为可能出现了拥塞。

慢开始的思路是：当主机开始发送数据时，由于不清楚网络的负荷情况，较好的办法是先探测一下，即由小增大拥塞窗口。具体为：
1. 通常在开始发送报文段时，将cwnd 设置为一个 MSS 的数值。
2. 每收到一个新的确认报文段，将 cwnd 增加一个 MSS 的数值。
3. 可以看出，每经过一个传输轮次，cwnd 就加倍。一个传输轮次所经历的时间其实就是往返 RTT,不过这里更加强调：把拥塞窗口所允许发送的报文段都连续发送出去，并收到对发送的最后一个字节的确认。
4. 慢开始的“慢”并不是指 cwnd 的增长速率慢，而是比起按照大的 cwnd 一下子将许多报文段突然注入到网络中要慢得多。这对于防止网络拥塞是一个非常有力的措施。

拥塞避免算法的思路是让 cwnd 缓慢地增大，即每经过一个 RTT 就把 cwnd 加一个MSS值(即只要收到一个新的确认，就把 cwnd 增加(MSS / cwnd * MSS)个字节)，而不是加倍。这样使得 cwnd 按线性规律缓慢增大，比慢开始算法的指数增长缓慢得多。

为了防止cwnd 增长过大引起网络拥塞，还需要设置一个慢开始门限状态变量。当cwnd < 慢开始门限值时，使用慢开始算法；反之则使用拥塞避免算法。

无论在慢开始阶段还是拥塞避免阶段，只要发送方判断出现网络拥塞，就将慢开始门限设置为出现拥塞时的发送窗口值的一半(有根据已发送出但还未确认的数据字节数来设置慢开始门限的新公式)，并将cwnd 值重设为 1,执行慢开始算法。这样做可以迅速减少网络中的分组数。

所有慢开始和拥塞避免的流程为：
1. TCP 连接进行初始化时，将 cwnd 置为 MSS值，并设置慢开始门限的初始值(如 16 * MSS)。
2. 执行慢开始算法，当cwnd 增长到值为慢开始门限值时，就使用拥塞避免算法。
3. 当网络出现超时重传后，将慢开始门限值更新为当前拥塞窗口值的一半，拥塞窗口值置为1，并执行慢开始算法重复 1,2,3。
![慢开始和拥塞避免例](/Image/congestion.PNG)

在TCP拥塞控制中常有"乘法减小，加法增大"的说法。乘法减小指不论是在慢开始还是在拥塞避免阶段，只要出现超时，就将慢开始门限减半，当网络频繁出现拥塞时，慢开始门限会下降得很快，可以大大减少注入网络中的分组数。加法增大则是指执行拥塞避免算法时，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。二者合称AIMD算法，使用最为广泛。

###### 5.8.2.2 快重传和快恢复
快重传算法首先要求接收方每收到一个**失序的报文段**后就立即发出重复确认，目的就是使发送方及早直到有报文段没有到达对方。除了第一个之外，之后的都是重复确认。快重传算法规定：发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待该报文段设置的重传计时器到期。

与快重传配置使用的还有快恢复算法：
1. 当发送方连续收到三个重复确认时，执行"乘法减小"算法将慢开始门限减半。这是为了预防网络拥塞，但接下去不执行慢开始算法。
2. 若出现拥塞，则不会一连好几个报文段连续到达接收方，也就不会导致接收方连续发送重复确认，因此此时发送方认为网络很可能没有拥塞。所以接下来是把cwnd 值设置为慢开始门限减半后的数值(也有的实现是设置为慢开始门限减半后的数值 + 3 * MSS)，然后开始执行拥塞避免算法。
3. 采用快恢复算法时，慢开始算法只是在TCP连接建立和网络出现超时时才使用，采用这样的拥塞控制方法使得TCP的性能有明显的改进。




### 6 应用层
应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层的数据单元是报文(message)

参考：
- https://juejin.im/post/5de372c2f265da060078039a
- https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%B8%83%E5%B1%82%E5%8D%8F%E8%AE%AE


bit Mb 
数据链路层差错检测丢弃，而传输层差错检测要重传